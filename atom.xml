<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>丹青两幻</title>
  
  <subtitle>欢迎~</subtitle>
  <link href="https://wangak.cc/atom.xml" rel="self"/>
  
  <link href="https://wangak.cc/"/>
  <updated>2023-12-10T00:00:00.000Z</updated>
  <id>https://wangak.cc/</id>
  
  <author>
    <name>丹青两幻</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>games作业4</title>
    <link href="https://wangak.cc/posts/db707014.html"/>
    <id>https://wangak.cc/posts/db707014.html</id>
    <published>2023-12-09T16:00:00.000Z</published>
    <updated>2023-12-10T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="递归绘制贝塞尔曲线"><a href="#递归绘制贝塞尔曲线" class="headerlink" title="递归绘制贝塞尔曲线"></a>递归绘制贝塞尔曲线</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">cv::Point2f recursive_bezier(const std::vector&lt;cv::Point2f&gt; &amp;control_points, float t) </span><br><span class="line">&#123;</span><br><span class="line">    if (control_points.size() == 1) </span><br><span class="line">    &#123;</span><br><span class="line">        return control_points[0];</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        std::vector&lt;cv::Point2f&gt; points;</span><br><span class="line">        for (int i = 0; i &lt; control_points.size()-1; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            cv::Point2f p;</span><br><span class="line">            p.x = (1-t) * control_points[i].x + t * control_points[i + 1].x;</span><br><span class="line">            p.y = (1-t) * control_points[i].y + t * control_points[i + 1].y;</span><br><span class="line">            points.push_back(p);</span><br><span class="line">        &#125;</span><br><span class="line">        return recursive_bezier(points, t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void bezier(const std::vector&lt;cv::Point2f&gt; &amp;control_points, cv::Mat &amp;window) </span><br><span class="line">&#123;</span><br><span class="line">    for (float t = 0; t &lt;= 1; t += 0.0001)</span><br><span class="line">    &#123;</span><br><span class="line">        //调用递归贝塞尔曲线计算函数，计算曲线上的点坐标</span><br><span class="line">        cv::Point2f point=recursive_bezier(control_points,t);</span><br><span class="line">        window.at&lt;cv::Vec3b&gt;(point.y, point.x)[1] = 255;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;递归绘制贝塞尔曲线&quot;&gt;&lt;a href=&quot;#递归绘制贝塞尔曲线&quot; class=&quot;headerlink&quot; title=&quot;递归绘制贝塞尔曲线&quot;&gt;&lt;/a&gt;递归绘制贝塞尔曲线&lt;/h3&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;t</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>光线追踪</title>
    <link href="https://wangak.cc/posts/426f6fb6.html"/>
    <id>https://wangak.cc/posts/426f6fb6.html</id>
    <published>2023-12-09T16:00:00.000Z</published>
    <updated>2023-12-10T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Shadow-Mapping"><a href="#1-Shadow-Mapping" class="headerlink" title="1.Shadow Mapping"></a>1.<strong>Shadow Mapping</strong></h3><p><strong>光栅化的问题：</strong>不能很好地表示全局的效果</p><p><strong>Shadow Mapping：</strong> 主要是为了解决点光源的硬阴影的问题</p><p>阴影区域：点对相机可见，而对光源不可见</p><p>Shadow Map记录每个pixel是否在阴影区域， 其生成步骤如下：</p><ul><li><p>1.从光源位置出发找出可见点，记录光源可见点的深度，得到光源深度图。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910765.png" alt="image-20231210115113668" style="zoom:50%;"></p></li><li><p>2.从相机出发，找可见点，如果点可见，坐标变换求此点到光源的距离。如果此距离与光源深度图中此位置的深度一致，说明此点可以被光源照到，是为光源、相机能同时看到点；如果不一致，说明是阴影点。</p></li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910506.png" alt="image-20231210115203873" style="zoom:50%;"></p><p><strong>硬阴影与软阴影：</strong></p><p>软阴影的形成在于全影和半影的渐变，点光源不存在软阴影问题，出现软阴影一定是光源有大小、不同照射位置有全影和半影这种渐变。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910061.png" alt="image-20231210120318890" style="zoom:50%;"></p><p>2.Whitted-Styled Ray Tracing</p><p><strong>光线追踪利用的就是光的可逆性</strong></p><p>利用递归的方法进行光线追踪，对每条光线，递归计算其多个弹射点，当前光线所对应的像素值是由全部弹射点共同决定的：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910583.png" alt="image-20231210124837928" style="zoom:50%;"></p><p><strong>光源的定义：起点+方向</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910866.png" alt="image-20231210124958832" style="zoom:50%;"></p><p>于是，光线上的点可表示为：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910939.png" alt="image-20231210125038746" style="zoom:50%;"></p><h3 id="3-光线求交点"><a href="#3-光线求交点" class="headerlink" title="3.光线求交点"></a>3.光线求交点</h3><h4 id="3-1-隐式表面"><a href="#3-1-隐式表面" class="headerlink" title="3.1 隐式表面"></a>3.1 隐式表面</h4><p>隐式表面求交点：将光线上的一点代入隐式方程中求解</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910802.png" alt="image-20231210125547229" style="zoom:50%;"></p><h4 id="3-2-显式表面"><a href="#3-2-显式表面" class="headerlink" title="3.2 显式表面"></a>3.2 显式表面</h4><p>显式表面求交点：用光线与三角形求交</p><p><strong>光线与三角形求交：</strong>光线与平面求交+判断交点是否在三角形内</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910771.png" alt="image-20231210130304291" style="zoom:50%;"></p><p>平面的定义：平面上一点+平面的法线</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910972.png" alt="image-20231210130407893" style="zoom:50%;"></p><p>求解交点的过程：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910503.png" alt="image-20231210130538694" style="zoom:50%;"></p><p><strong>Möller Trumbore Algorithm：</strong>三角形的一个点可以使用重心坐标表示</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910163.png" alt="image-20231210130920469" style="zoom:50%;"></p><p><em>注：解上图的方程，若$(1-b_1,b_2)、b_1、b_2$为正数，则交点在三角形内部</em></p><h3 id="4-计算的加速"><a href="#4-计算的加速" class="headerlink" title="4.计算的加速"></a>4.计算的加速</h3><p>每个光线与全部三角形都要进行求交点的计算，会导致计算开销过大，所以需要进行计算的加速。</p><p><strong>包围盒方法：</strong>在物体外面包一个包围盒，如果光线与盒子都没交点，那跟物体里的所有面更不会有交集。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910024.png" alt="image-20231210133306097" style="zoom:50%;"></p><p><strong>一般使用轴对齐包围盒（Axis-Aligned Bounding Box、AABB)</strong></p><p><strong>判断光线和包围盒是否有交点：</strong>通过计算光线进入/离开长方体的三个对面的时间可以判断出，光线和包围盒是否有交点</p><p>立方体有三个对面：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910471.png" alt="image-20231210133558734" style="zoom:50%;"></p><p>进入/离开对面的时间：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910723.png" alt="image-20231210133643427" style="zoom:50%;"></p><p>进入盒、离开盒的时间为：<br><img src="https://typoraimg.wangak.cc/2023/img/202312101910186.png" alt="image-20231210133737225" style="zoom:50%;"></p><p><em>注：光线进入了三个对面则认为光线进入了盒子，而光线离开了任意一个对面，就认为光线离开了盒子。</em></p><p><strong>若$t<em>{enter}&lt;t</em>{exit}且t_{exit}&gt;=0$，则有交点</strong></p><p><em>注：$t_{exit}$&lt;0，表示盒在光源背后，没有交点</em></p><h3 id="5-加速结构"><a href="#5-加速结构" class="headerlink" title="5.加速结构"></a>5.加速结构</h3><h4 id="5-1-均匀空间划分-Uniform-Spatial-Partitions-Grids"><a href="#5-1-均匀空间划分-Uniform-Spatial-Partitions-Grids" class="headerlink" title="5.1 均匀空间划分 Uniform Spatial Partitions (Grids)"></a>5.1 均匀空间划分 Uniform Spatial Partitions (Grids)</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910051.png" alt="image-20231210140725279" style="zoom:50%;"></p><p>判断光线交到的是不是含有物体表面的格子，如果不是的话跳过，是的话和其中的物体求交</p><p><em>注：该方法适合物体分布较均匀的场景</em></p><h4 id="5-2-空间划分"><a href="#5-2-空间划分" class="headerlink" title="5.2 空间划分"></a>5.2 空间划分</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910649.png" alt="image-20231210141331964" style="zoom:50%;"></p><ul><li>Oct-Tree:八叉树</li><li>KD-Tree</li><li>BSP-Tree</li></ul><p><strong>KD-Tree</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910636.png" alt="image-20231210142240300" style="zoom:50%;"></p><p>注：</p><p>1.KD-Tree中一个物体可能存在多个格子中</p><p>2.KD-Tree要计算三角形与盒子的求交，这较为困难</p><h4 id="5-3-物体划分（BVH）"><a href="#5-3-物体划分（BVH）" class="headerlink" title="5.3 物体划分（BVH）"></a>5.3 物体划分（BVH）</h4><p><strong>步骤：</strong></p><p>1.找到一个包围盒</p><p>2.递归地将物体拆成两个部分</p><p>3.两个部分重新计算包围盒</p><p>4.在每个叶子节点中记录实际的物体</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312101910732.png" alt="image-20231210143955688" style="zoom: 67%;"></p><p><em>注：划分规则：选择最长轴划分，以中间位置的物体进行划分</em></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-Shadow-Mapping&quot;&gt;&lt;a href=&quot;#1-Shadow-Mapping&quot; class=&quot;headerlink&quot; title=&quot;1.Shadow Mapping&quot;&gt;&lt;/a&gt;1.&lt;strong&gt;Shadow Mapping&lt;/strong&gt;&lt;/h3&gt;</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>图形学几何</title>
    <link href="https://wangak.cc/posts/e4365916.html"/>
    <id>https://wangak.cc/posts/e4365916.html</id>
    <published>2023-12-08T16:00:00.000Z</published>
    <updated>2023-12-09T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="图形学几何"><a href="#图形学几何" class="headerlink" title="图形学几何"></a>图形学几何</h2><h3 id="1-几何的分类"><a href="#1-几何的分类" class="headerlink" title="1.几何的分类"></a>1.几何的分类</h3><p><strong>隐式几何:</strong> 无明确表示，如用函数表示曲面，如点（x, y, z) 满足一定函数f(x, y)关系就在一个曲面上。判断点的位置关系很方便，遍历绘制图形比较困难。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536222.png" alt="image-20231209124852632" style="zoom:67%;"></p><p><strong>显式几何:</strong> 有明确表示方法，直接给出，或通过参数映射给出几何信息，比如一般的点云或网格。遍历绘制图形比较方便， 但判断点的位置关系，如内外、是否在表面上比较困难。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535257.png" alt="image-20231209124540218" style="zoom: 67%;"></p><p><em>注：显式几何的点被直接给出或可通过映射关系得到。</em></p><p><strong>区别：</strong>区别隐式曲面与显示曲面的关键就在于是否可以直接表示出所有的点</p><p><em>注：隐式曲面难以采样曲面上的点，但是可以轻易判断点与曲面的关系，对于显式曲面来可以很轻易的采样到所有的点，但是给予你任意一点却很难判断它与曲面的关系。</em></p><h4 id="1-1-隐式几何的例子"><a href="#1-1-隐式几何的例子" class="headerlink" title="1.1 隐式几何的例子"></a>1.1 隐式几何的例子</h4><ul><li><strong>代数曲面</strong></li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535303.png" alt="image-20231209125119599" style="zoom:67%;"></p><ul><li><strong>Constructive Solid Geometry(CSG):</strong>对各种不同的几何做布尔运算，如并，交，差</li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535351.png" alt="image-20231209125221199" style="zoom:67%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535535.png" alt="image-20231209125238367" style="zoom:67%;"></p><ul><li><strong>距离函数:</strong>得到几何体的混合效果</li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535344.png" alt="image-20231209125458243" style="zoom:67%;"></p><ul><li><strong>水平集：</strong>找出函数值为0的地方作为曲线</li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535748.png" alt="image-20231209125824432" style="zoom:67%;"></p><ul><li><strong>分型几何：</strong>通过迭代、自相似性和尺度不变性来描述复杂的几何形状。</li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535549.png" alt="image-20231209125952472" style="zoom: 50%;"></p><h4 id="1-2-显式几何的例子"><a href="#1-2-显式几何的例子" class="headerlink" title="1.2 显式几何的例子"></a>1.2 显式几何的例子</h4><ul><li><p><strong>点云：</strong>（x,y,z）的列表，用点代替面，可用于表示任何空间中的几何</p></li><li><p><strong>多边形面/三角形</strong>（使用的最广泛）</p></li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535443.png" alt="image-20231209130844203" style="zoom: 33%;"></p><p>用.obj格式的文件保存模型：顶点、法线、纹理坐标</p><p>如下，文件描述了一个立方体：8个顶点、6个法线（右图vn有8个是因为存在冗余）、纹理坐标（vt）</p><p>f:顶点/纹理坐标/法线,定义了哪三个顶点构成三角形</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535311.png" alt="image-20231209131213798" style="zoom:67%;"></p><h3 id="2-曲线"><a href="#2-曲线" class="headerlink" title="2.曲线"></a>2.曲线</h3><h4 id="2-1-贝塞尔曲线"><a href="#2-1-贝塞尔曲线" class="headerlink" title="2.1 贝塞尔曲线"></a>2.1 贝塞尔曲线</h4><p>贝塞尔曲线：用控制点去定义曲线</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535440.png" alt="image-20231209132251079" style="zoom: 33%;"></p><p><strong>de Casteljau Algorithm：</strong>画贝塞尔曲线</p><p>将问题转化为：t点该如何画</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535451.png" alt="image-20231209132632421" style="zoom:50%;"></p><p>由$b_0、b_1$得到$b_0^1$,$b_1、b_2$得到$b_1^1$,由$b_0^1$,$b_1^1$得到$b_0^2$,即为t点</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535890.png" alt="image-20231209132826273" style="zoom:50%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312100940592.png" alt="image-20231210094017798" style="zoom:50%;"></p><p>四个点的情况：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535312.png" alt="image-20231209133247407" style="zoom: 33%;"></p><p>给出n个控制点可以得到一个n阶的贝塞尔曲线：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091535895.png" alt="image-20231209133842896" style="zoom: 50%;"></p><p><strong>伯恩斯坦多项式：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536748.png" alt="image-20231209134013528" style="zoom:50%;"></p><p><em>注：(n,i)是组合数</em></p><p>贝塞尔曲线的性质：</p><p>(1).必定经过起始与终止控制点<br>(2).必定经与起始与终止线段相切<br>(3).具有仿射变换性质，可以通过移动控制点移动整条曲线<br>(4).凸包性质，曲线一定不会超出所有控制点构成的多边形范围</p><p><em>注：将t从0到1进行迭代即可得到完整的贝塞尔曲线</em></p><p><strong>逐段定义贝塞尔曲线：</strong>更易使用控制点去控制曲线（常用四个控制点定义一段贝塞尔曲线）</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536926.png" alt="image-20231209135657494" style="zoom:50%;"></p><h4 id="2-2-B样条"><a href="#2-2-B样条" class="headerlink" title="2.2 B样条"></a>2.2 B样条</h4><p>pass</p><h4 id="2-3-NURBS"><a href="#2-3-NURBS" class="headerlink" title="2.3 NURBS"></a>2.3 NURBS</h4><p>pass</p><h3 id="3-曲面"><a href="#3-曲面" class="headerlink" title="3.曲面"></a>3.曲面</h3><p><strong>贝塞尔曲面：</strong>需要有两个参数控制（时间u,v）,分别控制两次贝塞尔曲线的计算</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536201.png" alt="image-20231209142717655" style="zoom: 33%;"></p><h3 id="4-曲面细分"><a href="#4-曲面细分" class="headerlink" title="4.曲面细分"></a>4.曲面细分</h3><h4 id="4-1-Loop细分"><a href="#4-1-Loop细分" class="headerlink" title="4.1 Loop细分"></a>4.1 Loop细分</h4><p><strong>步骤：</strong></p><p><strong>1.生成更多三角形或顶点</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536280.png" alt="image-20231209144613202" style="zoom: 50%;"></p><p><strong>2.调整这些三角形的位置（顶点的位置）</strong></p><p>顶点分为两类，一类是新生成的顶点，一类是老的原来就有的顶点</p><p>对于新生成的顶点：其位置为周围顶点的权重之和</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536826.png" alt="image-20231209145401431" style="zoom:33%;"></p><p>对于旧的顶点：自身以及邻接顶点的权重和，权重的设置与旧的顶点的度有关</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536368.png" alt="image-20231209145809889" style="zoom:50%;"></p><h4 id="4-2-Catmull-Clark细分"><a href="#4-2-Catmull-Clark细分" class="headerlink" title="4.2 Catmull-Clark细分"></a>4.2 Catmull-Clark细分</h4><p>用于处理四边形面和三角面的混合的细分</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536889.png" alt="image-20231209150626897" style="zoom:50%;"></p><p><strong>Non-quad face:</strong>非四边形面</p><p><strong>奇异点:</strong>所有度不为4的顶点</p><p><strong>第一次细分所有面都会变成四边形，增加的奇异点个数为非四边形面的个数，之后再进行细分，奇异点个数不再增加</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536250.png" alt="image-20231209150826085" style="zoom:50%;"></p><p>点位置的调整：所有点分为：边上的点、面上的点、原来的点</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536387.png" alt="image-20231209151144071" style="zoom:50%;"></p><h3 id="5-曲面简化-Mesh-Smplication"><a href="#5-曲面简化-Mesh-Smplication" class="headerlink" title="5.曲面简化(Mesh Smplication)"></a>5.曲面简化(Mesh Smplication)</h3><p><strong>边坍缩：</strong>将一条边的两个顶点合成为一个顶点</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536794.png" alt="image-20231209152028718" style="zoom:50%;"></p><p>如何坍缩：使二次误差度量最小</p><p>二次误差度量：坍缩之后蓝色新顶点所在的位置与原来各个平面的垂直距离之和</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312091536192.png" alt="image-20231209152333304"></p><p><strong>步骤：</strong>（使用堆结构）</p><p><strong>1 为模型每条边赋值，其值为坍缩这条边之后，代替两个老顶点的新顶点所能得到的最小二次误差度量</strong><br> <strong>2 选取权值最小的边做坍缩，新顶点位置为原来计算得出使得二次误差最小的位置</strong><br> <strong>3 坍缩完之后，与之相连其他的边的位置会改动，更新这些边的权值</strong><br> <strong>4 重复上述步骤，直到到达终止条件</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;图形学几何&quot;&gt;&lt;a href=&quot;#图形学几何&quot; class=&quot;headerlink&quot; title=&quot;图形学几何&quot;&gt;&lt;/a&gt;图形学几何&lt;/h2&gt;&lt;h3 id=&quot;1-几何的分类&quot;&gt;&lt;a href=&quot;#1-几何的分类&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>games作业3</title>
    <link href="https://wangak.cc/posts/4514e5b7.html"/>
    <id>https://wangak.cc/posts/4514e5b7.html</id>
    <published>2023-12-02T16:00:00.000Z</published>
    <updated>2023-11-28T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-透视投影变换"><a href="#1-透视投影变换" class="headerlink" title="1.透视投影变换"></a>1.透视投影变换</h4><p>投影接口的参数是张角fov，横纵比为aspect时，透视投影的变换矩阵如下：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312090851755.png" alt="image-20231203092505302" style="zoom:50%;"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Eigen::Matrix4f get_projection_matrix(float eye_fov, float aspect_ratio, float zNear, float zFar)</span><br><span class="line">&#123;</span><br><span class="line">    Eigen::Matrix4f projection = Eigen::Matrix4f::Identity();</span><br><span class="line">    projection(0, 0) = -(1 / (aspect_ratio * tan(eye_fov / 180.0 * MY_PI)));</span><br><span class="line">    projection(1, 1) = -(1 / (tan(eye_fov / 180.0 * MY_PI)));</span><br><span class="line">    projection(2, 2) = (zNear + zFar) / (zNear - zFar);</span><br><span class="line">    projection(2, 3) = (2 * zFar * zNear) / (zNear - zFar);</span><br><span class="line">    projection(3, 2) = 1;</span><br><span class="line">    projection(3, 3) = 0;</span><br><span class="line">    return projection;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-判断点是否在三角形内"><a href="#2-判断点是否在三角形内" class="headerlink" title="2.判断点是否在三角形内"></a>2.判断点是否在三角形内</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">static bool insideTriangle(int x, int y, const Vector4f* _v)&#123;</span><br><span class="line">    Eigen::Vector2f AB, BC, CA, AP, BP, CP, p;</span><br><span class="line">    float a, b, c;//用于保存叉乘的结果(是正还是负）</span><br><span class="line">    p &lt;&lt; x ,y;</span><br><span class="line">    AB = _v[1].head(2) - _v[0].head(2);</span><br><span class="line">    AP = p - _v[0].head(2);</span><br><span class="line">    BC = _v[2].head(2) - _v[1].head(2);</span><br><span class="line">    BP = p - _v[1].head(2);</span><br><span class="line">    CA = _v[0].head(2) - _v[2].head(2);</span><br><span class="line">    CP = p - _v[2].head(2);</span><br><span class="line">    //分别计算叉乘，x,y方向为0，故只计算z方向的结果</span><br><span class="line">    a = AB[0] * AP[1] - AB[1] * AP[0];</span><br><span class="line">    b = BC[0] * BP[1] - BC[1] * BP[0];</span><br><span class="line">    c = CA[0] * CP[1] - CA[1] * CP[0];</span><br><span class="line">    if (a &gt; 0 &amp;&amp; b &gt; 0 &amp;&amp; c &gt; 0)</span><br><span class="line">        return true;</span><br><span class="line">    else if (a &lt; 0 &amp;&amp; b &lt; 0 &amp;&amp; c &lt; 0)</span><br><span class="line">        return true;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-光栅化"><a href="#3-光栅化" class="headerlink" title="3.光栅化"></a>3.光栅化</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">//屏幕空间光栅化</span><br><span class="line">//view_pos：顶点在屏幕空间的坐标</span><br><span class="line">void rst::rasterizer::rasterize_triangle(const Triangle&amp; t, const std::array&lt;Eigen::Vector3f, 3&gt;&amp; view_pos)</span><br><span class="line">&#123;</span><br><span class="line">    auto v = t.toVector4();</span><br><span class="line">    float x_max = std::max(std::max(v[0].x(), v[1].x()), v[2].x());</span><br><span class="line">    float x_min = std::min(std::min(v[0].x(), v[1].x()), v[2].x());</span><br><span class="line">    float y_min = std::min(std::min(v[0].y(), v[1].y()), v[2].y());</span><br><span class="line">    float y_max = std::max(std::max(v[0].y(), v[1].y()), v[2].y());</span><br><span class="line">    for (int i = x_min; i &lt; x_max+1; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j = y_min; j &lt; y_max+1; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            if (insideTriangle(i, j, t.v))</span><br><span class="line">            &#123;</span><br><span class="line">                //计算当前像素在三角形内的重心坐标</span><br><span class="line">                auto [alpha, beta, gamma] = computeBarycentric2D(i, j, t.v);</span><br><span class="line"></span><br><span class="line">                //通过重心插值得到深度值z_interpolated</span><br><span class="line">                //w_reciprocal为透视修正系数</span><br><span class="line">                float w_reciprocal = 1.0 / (alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w());</span><br><span class="line">                float z_interpolated = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w();</span><br><span class="line">                z_interpolated *= w_reciprocal;</span><br><span class="line"></span><br><span class="line">                //Z-Buffer</span><br><span class="line">                if (depth_buf[get_index(i, j)] &gt; z_interpolated)</span><br><span class="line">                &#123;</span><br><span class="line">                    //利用重心坐标插值颜色、法线、纹理、shadingcoords（像素位置）</span><br><span class="line">                    auto interpolated_color = interpolate(alpha, beta, gamma, t.color[0], t.color[1], t.color[2], 1);</span><br><span class="line">                    auto interpolated_normal = interpolate(alpha, beta, gamma, t.normal[0], t.normal[1], t.normal[2], 1);</span><br><span class="line">                    auto interpolated_texcoords = interpolate(alpha, beta, gamma, t.tex_coords[0], t.tex_coords[1], t.tex_coords[2], 1);</span><br><span class="line">                    auto interpolated_shadingcoords = interpolate(alpha, beta, gamma, view_pos[0], view_pos[1], view_pos[2], 1);</span><br><span class="line">                    // 初始化 payload，用于传递给片段着色器</span><br><span class="line">                    fragment_shader_payload payload(interpolated_color, interpolated_normal.normalized(), interpolated_texcoords, texture ? &amp;*texture : nullptr);</span><br><span class="line">                    payload.view_pos = interpolated_shadingcoords;</span><br><span class="line"></span><br><span class="line">                    // 更新深度缓存</span><br><span class="line">                    depth_buf[get_index(i, j)] = z_interpolated;</span><br><span class="line"></span><br><span class="line">                    // 设置像素颜色，调用片段着色器</span><br><span class="line">                    Vector2i temp(i, j);</span><br><span class="line">                    set_pixel(temp, fragment_shader(payload));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-Blinn-Phong反射模型"><a href="#4-Blinn-Phong反射模型" class="headerlink" title="4.Blinn-Phong反射模型"></a>4.Blinn-Phong反射模型</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Eigen::Vector3f phong_fragment_shader(const fragment_shader_payload&amp; payload)</span><br><span class="line">&#123;</span><br><span class="line">    Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);//环境光反射率</span><br><span class="line">    Eigen::Vector3f kd = payload.color;//漫反射项系数</span><br><span class="line">    Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);//高光项</span><br><span class="line">    //定义了两个光源</span><br><span class="line">    auto l1 = light&#123;&#123;20, 20, 20&#125;, &#123;500, 500, 500&#125;&#125;;</span><br><span class="line">    auto l2 = light&#123;&#123;-20, 20, 0&#125;, &#123;500, 500, 500&#125;&#125;;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;light&gt; lights = &#123;l1, l2&#125;;</span><br><span class="line">    Eigen::Vector3f amb_light_intensity&#123;10, 10, 10&#125;;//环境光</span><br><span class="line">    Eigen::Vector3f eye_pos&#123;0, 0, 10&#125;;//观察点的位置</span><br><span class="line">    float p = 150;</span><br><span class="line"></span><br><span class="line">    Eigen::Vector3f color = payload.color;</span><br><span class="line">    Eigen::Vector3f point = payload.view_pos;</span><br><span class="line">    Eigen::Vector3f normal = payload.normal;</span><br><span class="line"></span><br><span class="line">    Eigen::Vector3f result_color = &#123;0, 0, 0&#125;;</span><br><span class="line">    for (auto&amp; light : lights)</span><br><span class="line">    &#123;</span><br><span class="line">        //计算光源到物体距离的平方r2</span><br><span class="line">        float r2 = (light.position - point).dot((light.position - point));//a.dot(a)=|a|^2</span><br><span class="line"></span><br><span class="line">        Eigen::Vector3f l = (light.position - point).normalized();//光线方向</span><br><span class="line">        Eigen::Vector3f v = (eye_pos - point).normalized();//观察方向</span><br><span class="line">        Eigen::Vector3f h = (l + v).normalized();//半程向量</span><br><span class="line"></span><br><span class="line">        //.cwiseProduct()用于向量对应位置的点相乘</span><br><span class="line">        //漫反射</span><br><span class="line">        Eigen::Vector3f diffuse = kd.cwiseProduct(light.intensity / r2) * std::max(0.0f, normal.normalized().dot(l));</span><br><span class="line">        //环境光</span><br><span class="line">        Eigen::Vector3f ambient = ka.cwiseProduct(amb_light_intensity);</span><br><span class="line">        //高光</span><br><span class="line">        Eigen::Vector3f specular = ks.cwiseProduct(light.intensity / r2) * pow(std::max(0.0f, normal.normalized().dot(h)), p);</span><br><span class="line"></span><br><span class="line">        result_color += ambient + diffuse + specular; </span><br><span class="line">    &#125;</span><br><span class="line">    return result_color * 255.f;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5-纹理映射"><a href="#5-纹理映射" class="headerlink" title="5.纹理映射"></a>5.纹理映射</h4><p>修改漫反射系数 <code>kd</code>即可，<code>kd</code> 是一个颜色向量，它表示了表面对漫反射光的反应程度，环境光和镜面反射成分通常是不受纹理映射直接影响。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">Eigen::Vector3f texture_fragment_shader(const fragment_shader_payload&amp; payload)</span><br><span class="line">&#123;</span><br><span class="line">    Eigen::Vector3f return_color = &#123;0, 0, 0&#125;;</span><br><span class="line">    if (payload.texture)</span><br><span class="line">    &#123;</span><br><span class="line">        //获取纹理坐标处的颜色</span><br><span class="line">        return_color = payload.texture-&gt;getColor(payload.tex_coords.x(), payload.tex_coords.y());</span><br><span class="line">    &#125;</span><br><span class="line">    Eigen::Vector3f texture_color;</span><br><span class="line">    texture_color &lt;&lt; return_color.x(), return_color.y(), return_color.z();</span><br><span class="line"></span><br><span class="line">    Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);</span><br><span class="line">    Eigen::Vector3f kd = texture_color / 255.f;</span><br><span class="line">    Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);</span><br><span class="line"></span><br><span class="line">    auto l1 = light&#123;&#123;20, 20, 20&#125;, &#123;500, 500, 500&#125;&#125;;</span><br><span class="line">    auto l2 = light&#123;&#123;-20, 20, 0&#125;, &#123;500, 500, 500&#125;&#125;;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;light&gt; lights = &#123;l1, l2&#125;;</span><br><span class="line">    Eigen::Vector3f amb_light_intensity&#123;10, 10, 10&#125;;</span><br><span class="line">    Eigen::Vector3f eye_pos&#123;0, 0, 10&#125;;</span><br><span class="line"></span><br><span class="line">    float p = 150;</span><br><span class="line">    Eigen::Vector3f color = texture_color;</span><br><span class="line">    Eigen::Vector3f point = payload.view_pos;</span><br><span class="line">    Eigen::Vector3f normal = payload.normal;</span><br><span class="line"></span><br><span class="line">    Eigen::Vector3f result_color = &#123;0, 0, 0&#125;;</span><br><span class="line"></span><br><span class="line">    for (auto&amp; light : lights)</span><br><span class="line">    &#123;</span><br><span class="line">        //计算光源到物体距离的平方r2</span><br><span class="line">        float r2 = (light.position - point).dot((light.position - point));//a.dot(a)=|a|^2</span><br><span class="line"></span><br><span class="line">        Eigen::Vector3f l = (light.position - point).normalized();//光线方向</span><br><span class="line">        Eigen::Vector3f v = (eye_pos - point).normalized();//观察方向</span><br><span class="line">        Eigen::Vector3f h = (l + v).normalized();//半程向量</span><br><span class="line"></span><br><span class="line">        //.cwiseProduct()用于向量对应位置的点相乘</span><br><span class="line">        //漫反射</span><br><span class="line">        Eigen::Vector3f diffuse = kd.cwiseProduct(light.intensity / r2) * std::max(0.0f, normal.normalized().dot(l));</span><br><span class="line">        //环境光</span><br><span class="line">        Eigen::Vector3f ambient = ka.cwiseProduct(amb_light_intensity);</span><br><span class="line">        //高光</span><br><span class="line">        Eigen::Vector3f specular = ks.cwiseProduct(light.intensity / r2) * pow(std::max(0.0f, normal.normalized().dot(h)), p);</span><br><span class="line"></span><br><span class="line">        result_color += ambient + diffuse + specular;</span><br><span class="line">    &#125;</span><br><span class="line">    return result_color * 255.f;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6-凹凸贴图"><a href="#6-凹凸贴图" class="headerlink" title="6.凹凸贴图"></a>6.凹凸贴图</h4><p>pass</p><h4 id="7-位移贴图"><a href="#7-位移贴图" class="headerlink" title="7.位移贴图"></a>7.位移贴图</h4><p>pass</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;1-透视投影变换&quot;&gt;&lt;a href=&quot;#1-透视投影变换&quot; class=&quot;headerlink&quot; title=&quot;1.透视投影变换&quot;&gt;&lt;/a&gt;1.透视投影变换&lt;/h4&gt;&lt;p&gt;投影接口的参数是张角fov，横纵比为aspect时，透视投影的变换矩阵如下：&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>纹理映射</title>
    <link href="https://wangak.cc/posts/df375b66.html"/>
    <id>https://wangak.cc/posts/df375b66.html</id>
    <published>2023-12-01T00:00:00.000Z</published>
    <updated>2023-12-01T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-纹理映射"><a href="#1-纹理映射" class="headerlink" title="1.纹理映射"></a>1.纹理映射</h3><p><strong>纹理映射：</strong>用于增强渲染的真实感和细节，允许在三维模型表面上贴附二维图像，以模拟材质、颜色、光照等细节。</p><p>纹理坐标的伪代码表示：<br><img src="https://typoraimg.wangak.cc/2023/img/202312090856218.png" alt="image-20231201125433593" style="zoom:50%;"></p><p>​        即通过对每个光栅化的屏幕坐标算出它的纹理坐标（u,v)(利用三角形顶点重心坐标插值),再利用这个u,v坐标去查询texture上的颜色，把这个颜色信息当作漫反射系数Kd。</p><h4 id="1-1-纹理过小的问题"><a href="#1-1-纹理过小的问题" class="headerlink" title="1.1 纹理过小的问题"></a>1.1 纹理过小的问题</h4><p><strong>问题：</strong>例如，有一张大小为100x100像素的纹理贴图，然后将这个贴图应用到一个500x500像素的屏幕上，这样多个像素点可能会映射到纹理贴图的相同区域，这使得纹理像素的信息被多个屏幕像素所共享。</p><p>​        如果只是简单地使用最近的纹理坐标点，即离目标点最近的(u, v)坐标，取样不足以准确反映屏幕上多个像素的信息，会导致渲染结果出现严重的走样问题。</p><p><strong>解决方法：</strong>使用更复杂的纹理过滤技术，如双线性插值，考虑周围像素的颜色信息，从而在渲染过程中更加平滑地处理纹理映射，减少走样的影响。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312090856478.png" alt="image-20231201130205648" style="zoom:50%;"></p><p><em>注：Bicubic：双三次插值是利用三次方程来进行两次插值，但是计算开销过</em>大</p><h4 id="1-2-纹理过大的问题"><a href="#1-2-纹理过大的问题" class="headerlink" title="1.2 纹理过大的问题"></a>1.2 纹理过大的问题</h4><p><strong>现象：</strong><br><img src="https://typoraimg.wangak.cc/2023/img/202312090855369.png" alt="image-20231201130738219" style="zoom: 67%;"></p><p><strong>近处出现锯齿，远处出现摩尔纹</strong></p><p><strong>原因：</strong>根据近大远小，远处的一张完整的贴图可能在屏幕空间中仅仅是几个像素的大小，屏幕空间的一个像素对应了纹理贴图上的一片范围的点，而用一个点采样的结果代替纹理空间一片范围的颜色信息，必然会导致严重失真</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312090855975.png" alt="image-20231201131153194" style="zoom:50%;"></p><p>如上图，一个屏幕空间的蓝色像素点离相机越远，对应在texture空间的范围也就越大</p><p><strong>解决方法：</strong>超采样（计算开销过大，不好）、MipMap</p><p><strong>纹理足迹（Texture Footprint）：</strong> 当纹理贴图映射到几何体表面时，每个像素在纹理空间中的足迹描述了纹理在几何体上的分布。</p><h4 id="1-3-MipMap"><a href="#1-3-MipMap" class="headerlink" title="1.3 MipMap"></a>1.3 MipMap</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202312090856328.png" alt="image-20231201132206220" style="zoom:50%;"></p><p>level 0代表的是原始texture，也是精度最高的纹理，随着level的提升，每提升一级将4个相邻像素点求均值合为一个像素点，因此越高的level也就代表了更大的footprint的区域查询。接下来要做的就是根据屏幕像素的footprint大小选定不同level的texture，再进行点查询即可，而这其实就相当于在原始texture上进行了区域查询。</p><p><em>注：通过MipMap将区域查询的问题，再次转换为点查询。使用MipMap仅将纹理map的大小扩大了1/3</em></p><p><strong>确定level：</strong>利用屏幕像素的相邻像素点估算footprint大小再确定level</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312090856671.png" alt="image-20231201132617242" style="zoom: 67%;"></p><p>在屏幕空间中取当前像素点的右方和上方的两个相邻像素点(4个全取也可以)，分别查询得到这3个点对应在Texture space的坐标，计算出当前像素点与右方像素点和上方像素点在Texture space的距离，二者取最大值得到L,再通过L得到D。</p><p><strong>D算出的是一个连续值而不是整数的解决办法：</strong><br>（1）四舍五入取得最近的那个level D（纹理之间可能存在突变，不连续，故不好）</p><p>（2）利用D值在向下和向上取整的两个不同level进行三线性插值（即将level连续化），如下图。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312090856929.png" alt="image-20231201133041710" style="zoom:50%;"></p><p>三线性插值的MipMap的效果：远处出现了过曝的现象<br><img src="https://typoraimg.wangak.cc/2023/img/202312090856355.png" alt="image-20231201133122841" style="zoom: 50%;"></p><p><em>出现该问题的原因是屏幕空间中的正方形的像素，在纹理空间中的形状可能是不规则的矩形</em></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312090856608.png" alt="image-20231201133312851" style="zoom:50%;"></p><h4 id="1-4-各向异性过滤Mipmap"><a href="#1-4-各向异性过滤Mipmap" class="headerlink" title="1.4 各向异性过滤Mipmap"></a>1.4 各向异性过滤Mipmap</h4><p>各向异性的过滤：<img src="https://typoraimg.wangak.cc/2023/img/202312090856102.png" alt="image-20231201133512182" style="zoom:50%;"></p><p>将纹理分为水平方向上的level和竖直方向的level</p><h3 id="2-凹凸贴图"><a href="#2-凹凸贴图" class="headerlink" title="2.凹凸贴图"></a>2.凹凸贴图</h3><p><strong>凹凸贴图的原理:</strong>  利用凹凸贴图来改变原本光滑的平面的法线, 使原本光滑的平面产生凹凸感。</p><p> pass</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-纹理映射&quot;&gt;&lt;a href=&quot;#1-纹理映射&quot; class=&quot;headerlink&quot; title=&quot;1.纹理映射&quot;&gt;&lt;/a&gt;1.纹理映射&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;纹理映射：&lt;/strong&gt;用于增强渲染的真实感和细节，允许在三维模型表面上贴附二维图像，以</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>games作业框架</title>
    <link href="https://wangak.cc/posts/b46ced9d.html"/>
    <id>https://wangak.cc/posts/b46ced9d.html</id>
    <published>2023-11-30T16:00:00.000Z</published>
    <updated>2023-12-01T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Triangle类"><a href="#1-Triangle类" class="headerlink" title="1.Triangle类"></a>1.Triangle类</h3><h4 id="1-1-Triangle-hpp：类的声明"><a href="#1-1-Triangle-hpp：类的声明" class="headerlink" title="1.1 Triangle.hpp：类的声明"></a>1.1 Triangle.hpp：类的声明</h4><p><strong>定义了一个名为 <code>Triangle</code> 的类</strong></p><ul><li>三角形顶点的齐次坐标：（x,y,z,w)</li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202312090858570.png" alt="image-20231203094213284"></p><p><em>注：w=0时表示该点在无穷远处</em></p><ul><li><strong>ifndef</strong>：防止头文件的重复包含，确保在编译时，同一个头文件不会被多次包含，从而避免因重复包含导致的重定义报错。</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> __TEST_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __TEST_H</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line"><span class="string">...... #内容</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line">头文件结尾写上一行：</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><p><em>注：__TEST_H为标识符，通常是大写形式</em></p><ul><li><strong>void setNormals(const std::array<Vector3f, 3>&amp; normals)</Vector3f,></strong>：利用normals设置三角形顶点的法向量normal[3]<ul><li>std::array：标准库中的容器</li><li>Vector3f（元素类型）、3（数组大小）</li><li>const:保证normals不会被修改,&amp;:传递引用类型，避免对象的拷贝，提高执行效率</li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#ifndef RASTERIZER_TRIANGLE_H</span><br><span class="line">#define RASTERIZER_TRIANGLE_H</span><br><span class="line"></span><br><span class="line">#include&lt;eigen3/Eigen/Eigen&gt;</span><br><span class="line">#include&quot;Texture.hpp&quot;//项目内的头文件用&quot;&quot;</span><br><span class="line">using namespace Eigen;</span><br><span class="line">class Triangle&#123;</span><br><span class="line">Vector4f v[3];//三角形三个顶点的其次坐标（x,y,z,w)</span><br><span class="line">Vector3f color[3];//顶点的颜色</span><br><span class="line">Vector2f tex_coords[3];//顶点的纹理坐标</span><br><span class="line">Vector3f normal[3];//顶点的法向量</span><br><span class="line"></span><br><span class="line">Texture* tex = nullptr;//指向其纹理信息的指针</span><br><span class="line"></span><br><span class="line">Triangle();//默认构造函数</span><br><span class="line"></span><br><span class="line">//获取三个顶点的坐标</span><br><span class="line">Eigen::Vector4f a() const &#123; return v[0]; &#125;</span><br><span class="line">Eigen::Vector4f b() const &#123; return v[1]; &#125;</span><br><span class="line">Eigen::Vector4f c() const &#123; return v[2]; &#125;</span><br><span class="line"></span><br><span class="line">//设置第i个顶点的坐标</span><br><span class="line">void setVertex(int ind,Vector4f ver);//将第i个顶点的坐标设置为ver</span><br><span class="line">//设置法向量</span><br><span class="line">void setNormal(int ind, Vector3f ver);</span><br><span class="line">//设置颜色</span><br><span class="line">void setColor(int ind, float r, float g, float b);</span><br><span class="line">//设置所有顶点的法向量</span><br><span class="line">void setNormals(const std::array&lt;Vector3f, 3&gt;&amp; normals);</span><br><span class="line">//设置所有顶点的颜色</span><br><span class="line">void setColors(const std::array&lt;Vector3f, 3&gt;&amp; colors);</span><br><span class="line">//设置第i个顶点的纹理</span><br><span class="line">void setTexCoord(int ind, Vector2f uv);</span><br><span class="line"></span><br><span class="line">std::array&lt;Vector4f, 3&gt; toVector4() const;//定义toVector4()函数，将齐次坐标（x,y,z,w)转换为（x/w,y/w,z/w,1)的形式</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">#endif // !RASTERIZER_TRIANGLE_H</span><br></pre></td></tr></table></figure><h4 id="1-2-Triangle-cpp：类的实现"><a href="#1-2-Triangle-cpp：类的实现" class="headerlink" title="1.2 Triangle.cpp：类的实现"></a>1.2 Triangle.cpp：类的实现</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">#include&quot;Triangle.hpp&quot;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;array&gt;</span><br><span class="line"></span><br><span class="line">//构造函数的实现</span><br><span class="line">Triangle::Triangle() &#123;</span><br><span class="line">v[0] &lt;&lt; 0, 0, 0, 1;</span><br><span class="line">v[1] &lt;&lt; 0, 0, 0, 1;</span><br><span class="line">v[2] &lt;&lt; 0, 0, 0, 1;</span><br><span class="line">color[0] &lt;&lt; 0.0, 0.0, 0.0;</span><br><span class="line">color[1] &lt;&lt; 0.0, 0.0, 0.0;</span><br><span class="line">color[2] &lt;&lt; 0.0, 0.0, 0.0;</span><br><span class="line">tex_coords[0] &lt;&lt; 0.0, 0.0;</span><br><span class="line">tex_coords[1] &lt;&lt; 0.0, 0.0;</span><br><span class="line">tex_coords[2] &lt;&lt; 0.0, 0.0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//设置指定索引的纹理</span><br><span class="line">void Triangle::setTexCoord(int ind, Vector2f uv) &#123;</span><br><span class="line">tex_coords[ind] = uv;</span><br><span class="line">&#125;</span><br><span class="line">//设置顶点</span><br><span class="line">void Triangle::setVertex(int ind, Vector4f ver) &#123;</span><br><span class="line">v[ind] = ver;</span><br><span class="line">&#125;</span><br><span class="line">//设置法线</span><br><span class="line">void Triangle::setNormal(int ind, Vector3f n) &#123;</span><br><span class="line">normal[ind] = n;</span><br><span class="line">&#125;</span><br><span class="line">//设置颜色</span><br><span class="line">void Triangle::setColor(int ind, float r, float g, float b) &#123;</span><br><span class="line">if ((r &lt; 0.0) || (r &gt; 255.) ||</span><br><span class="line">(g &lt; 0.0) || (g &gt; 255.) ||</span><br><span class="line">(b &lt; 0.0) || (b &gt; 255.)) &#123;</span><br><span class="line">fprintf(stderr, &quot;ERROR! Invalid color values&quot;);</span><br><span class="line">fflush(stderr);</span><br><span class="line">exit(-1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">color[ind] = Vector3f((float)r / 255., (float)g / 255., (float)b / 255.);</span><br><span class="line">return;</span><br><span class="line">&#125;</span><br><span class="line">//将顶点坐标转换为标准的四维齐次坐标</span><br><span class="line">std::array&lt;Vector4f, 3&gt; Triangle::toVector4() const</span><br><span class="line">&#123;</span><br><span class="line">std::array&lt;Vector4f, 3&gt; res;</span><br><span class="line">std::transform(std::begin(v), std::end(v), res.begin(), [](auto&amp; vec) &#123; return Vector4f(vec.x(), vec.y(), vec.z(), 1.f); &#125;);</span><br><span class="line">return res;</span><br><span class="line">&#125;</span><br><span class="line">void Triangle::setNormals(const std::array&lt;Vector3f, 3&gt;&amp; normals)</span><br><span class="line">&#123;</span><br><span class="line">// 设置法向量</span><br><span class="line">normal[0] = normals[0];</span><br><span class="line">normal[1] = normals[1];</span><br><span class="line">normal[2] = normals[2];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Triangle::setColors(const std::array&lt;Vector3f, 3&gt;&amp; colors)</span><br><span class="line">&#123;</span><br><span class="line">// 设置颜色</span><br><span class="line">auto first_color = colors[0];</span><br><span class="line">setColor(0, colors[0][0], colors[0][1], colors[0][2]);</span><br><span class="line">setColor(1, colors[1][0], colors[1][1], colors[1][2]);</span><br><span class="line">setColor(2, colors[2][0], colors[2][1], colors[2][2]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-Triangle类&quot;&gt;&lt;a href=&quot;#1-Triangle类&quot; class=&quot;headerlink&quot; title=&quot;1.Triangle类&quot;&gt;&lt;/a&gt;1.Triangle类&lt;/h3&gt;&lt;h4 id=&quot;1-1-Triangle-hpp：类的声明&quot;&gt;&lt;a hre</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>局部光照模型及着色方法</title>
    <link href="https://wangak.cc/posts/af9d8c8.html"/>
    <id>https://wangak.cc/posts/af9d8c8.html</id>
    <published>2023-11-29T16:00:00.000Z</published>
    <updated>2023-11-28T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-局部光照模型"><a href="#1-局部光照模型" class="headerlink" title="1.局部光照模型"></a>1.局部光照模型</h3><p><strong>光线的简单分类：</strong></p><ul><li><p><strong>镜面反射</strong></p></li><li><p><strong>漫反射</strong></p></li></ul><ul><li><strong>环境光</strong></li></ul><h4 id="1-1-泛光模型"><a href="#1-1-泛光模型" class="headerlink" title="1.1 泛光模型"></a>1.1 泛光模型</h4><p>泛光模型即<strong>只考虑环境光</strong>，这是最简单的<strong>经验</strong>模型，只会去考虑环境光的影响，并且不会去精确的描述，而只是用一个简单的式子表示：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952046.png" alt="image-20231130091038413" style="zoom:50%;"></p><script type="math/tex; mode=display">注：K_a表示物体表面对环境光的反射率，I_a代表入射环境光的亮度，I_{env}存储结果，即人眼所能看到从物体表面反射的环境光的亮度。</script><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952312.png" alt="image-20231130091806017" style="zoom: 67%;"></p><h4 id="1-2-Lambert漫反射模型"><a href="#1-2-Lambert漫反射模型" class="headerlink" title="1.2 Lambert漫反射模型"></a>1.2 Lambert漫反射模型</h4><ul><li><p>在泛光模型的基础之上增加了<strong>漫反射项</strong></p><ul><li>每个不同方向反射的光的强度相等</li><li>产生漫反射的原因是物体表面的粗糙</li></ul></li><li><p><strong>漫反射光照强度与光线照射方向和表面法线之间的夹角余弦成正比</strong></p><p><em>注：漫反射与观察方向无关，光线照射方向和表面法线之间的夹角反应了对于光照的接受率</em></p></li><li><p><strong>公式表示：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952975.png" alt="image-20231130091906700" style="zoom:50%;"></p></li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952973.png" alt="image-20231130091824267"></p><h4 id="1-3-Blinn-Phong反射模型"><a href="#1-3-Blinn-Phong反射模型" class="headerlink" title="1.3 Blinn-Phong反射模型"></a>1.3 Blinn-Phong反射模型</h4><p>Blinn-Phong反射模型是Phong光照模型的一种改进，在模拟高光方面表现更为自然。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952864.png" alt="image-20231130092346846" style="zoom: 50%;"></p><p>注：$k_s$为镜面反射系数， I为入射光强， r为光源到入射点距离,指数p加速衰减(用于减小可以看到高光的角度）</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952037.png" alt="image-20231130092850361" style="zoom:50%;"></p><p>注：使用半程向量简化了反射向量与人眼观察夹角的计算（Phong光照模型，即下图中R与v的夹角的计算）</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952906.png" alt="image-20231130092457821" style="zoom:50%;"></p><p><strong>整体计算公式：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300952426.png" alt="image-20231130092944573" style="zoom:50%;"></p><p><em>注：L=泛光（环境光）+漫反射项+高光</em></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300953544.png" alt="image-20231130093045061" style="zoom:50%;"></p><h3 id="2-着色方法-频率"><a href="#2-着色方法-频率" class="headerlink" title="2.着色方法(频率)"></a>2.着色方法(频率)</h3><h4 id="2-1-Flat-Shading（面着色）"><a href="#2-1-Flat-Shading（面着色）" class="headerlink" title="2.1 Flat Shading（面着色）"></a>2.1 Flat Shading（面着色）</h4><p>模型数据大多以很多个三角面进行存储，因此也就记录了每个面的法线向量，利用每个面的法线向量进行一次Blinn-Phong反射光照模型的计算，将该颜色赋予整个面。</p><p>效果如下：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300953328.png" alt="image-20231130093503703" style="zoom:50%;"></p><h4 id="2-2-Gouraud-Shading（顶点着色）"><a href="#2-2-Gouraud-Shading（顶点着色）" class="headerlink" title="2.2 Gouraud Shading（顶点着色）"></a>2.2 Gouraud Shading（顶点着色）</h4><p>Gouraud Shading会对每个三角形的顶点进行一次着色</p><p><strong>点法线：将所有共享这个点的面的法线向量加起来求均值，最后再标准化</strong></p><p><strong>三角形内部的每一个点：</strong>利用<strong>重心坐标来插值</strong></p><p>重心坐标：给定的三角形ABC和其中的一个点P，其重心坐标$(w_a,w_b,w_c)$满足以下条件：</p><ul><li>$w_a+w_b+w_c=1$</li><li>$P=w_a⋅A+w_b⋅B+w_c⋅C$</li></ul><p>重心坐标可以通过面积的比值求出：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312010916393.png" alt="image-20231130134307989" style="zoom:50%;"></p><p>注：三角形的重心为（1/3，1/3，1/3），其将三角形分为了面积相等的三份。</p><p>重心坐标一般的表达式：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312010916494.png" alt="image-20231130134715691" style="zoom:50%;"></p><p>重心插值公式如下:</p><p>$P_{interpolated}=w_a⋅P_A+w_b⋅P_B+w_c⋅P_C$</p><p><em>注：$P_A、P_B、P_C$分别是三个顶点上的属性值</em></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300953992.png" alt="image-20231130094402265" style="zoom:50%;"></p><p><em>注：重心坐标经过投影之后可能会改变，在三维空间中插值一些属性时，要计算三维空间中重心的坐标。</em></p><h4 id="2-3-Phong-Shading-像素着色"><a href="#2-3-Phong-Shading-像素着色" class="headerlink" title="2.3 Phong Shading(像素着色)"></a>2.3 Phong Shading(像素着色)</h4><p>要对每个点都进行光照计算，三角形内部的每一个点的法线向量如插值颜色一样得到：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300953798.png" alt="image-20231130094638524" style="zoom:50%;"></p><p><em>注：$n_0,n_1,n_2$分别是三角形三个顶点的法线向量,α,β,γ为三角形面内点的重心坐标</em></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311300953475.png" alt="image-20231130094743068" style="zoom:50%;"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-局部光照模型&quot;&gt;&lt;a href=&quot;#1-局部光照模型&quot; class=&quot;headerlink&quot; title=&quot;1.局部光照模型&quot;&gt;&lt;/a&gt;1.局部光照模型&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;光线的简单分类：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;str</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>SG-Former</title>
    <link href="https://wangak.cc/posts/c53f4cce.html"/>
    <id>https://wangak.cc/posts/c53f4cce.html</id>
    <published>2023-11-29T16:00:00.000Z</published>
    <updated>2023-11-29T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SG-Former"><a href="#SG-Former" class="headerlink" title="SG-Former"></a>SG-Former</h2><p><strong>论文：《SG-Former: Self-guided Transformer with Evolving Token Reallocation》（ICCV 2023)</strong></p><h4 id="1-探究动机"><a href="#1-探究动机" class="headerlink" title="1.探究动机"></a>1.探究动机</h4><p>ViT使用全局的自注意力机制，但带来了较高的计算成本。</p><p>Swin Transformer设计了窗口注意力，而牺牲了建模全局信息的能力。</p><p><strong>提出SG-Fomer（Self-guided Transformer):</strong>利用<strong>显著性</strong>图，根据每个区域的显著性来分配token，将更多的token分配给显著性区域以获取细粒度的注意力，而将更少的token分配给次要的区域以换取计算效率和全局的感受野。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145871.png" alt="image-20231130202913356"></p><p><em>注：在显著性区域（狗脸）分配更多的token</em></p><h4 id="2-网络设计"><a href="#2-网络设计" class="headerlink" title="2.网络设计"></a>2.网络设计</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145135.png" alt="image-20231130203138889" style="zoom:80%;"></p><p><strong>Hybrid-Scale Transformer blocks:</strong>提取多尺度的信息并为Self-Guided Transformer Block提供显著性图</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145630.png" alt="image-20231129153810548" style="zoom: 67%;"></p><p>把H个注意力头分成h组，在第j组的注意力头有一个尺度因子<script type="math/tex">S_j</script>,即对于K,V的每<script type="math/tex">S_j*S_j</script>个token合并为一个token，把K、V的窗口大小设为M,Q的窗口大小设为<script type="math/tex">S_jM*S_jM</script>(使Q中token与K、V中的token对齐）</p><p><em>注：</em></p><p><em>（1）K,V的窗口大小在所有组中都是固定的，均为M,而Q的窗口大小还和$S_j$有关</em>，每一组的输出均为N*M,N为token序列的长度</p><p><em>（2）token的合并是通过卷积实现的</em></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145504.png" alt="image-20231130205331048" style="zoom: 67%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145396.png" alt="image-20231130205438728" style="zoom: 67%;"></p><p>Token 的重要性被视为所有 Token 和当前 Token 的乘积之和：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145068.png" alt="image-20231129153230302" style="zoom: 67%;"></p><p><em>注：S是对所有的$S_i$求和的结果，即为最终的注意力图，用于混合尺度引导</em></p><p><strong>Self-Guided Transformer Block：</strong></p><p>为了降低计算成本，同时保持计算后特征映射的大小不变，固定Q的大小，使用IAM（importance guided aggregation module)对K和V的token进行聚合</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145350.png" alt="image-20231130211007377" style="zoom: 80%;"></p><p><em>注：S为显著性图，r为合并比率</em></p><p>将S平均分为n个子区域S1，S2,……Sn,每个区域设置不同的合并比率r1,r2,……，rn,子区域越重要，合并比率越小，输入特征X按X1,X2,……,Xn分组，每组有不同的合并比率</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311302145872.png" alt="image-20231130212526902" style="zoom: 67%;"></p><p><em>注：token的合并通过全连接层实现</em></p><h4 id="3-实验"><a href="#3-实验" class="headerlink" title="3.实验"></a>3.实验</h4><p>与其他结构在语义分割任务中的对比：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312010859765.png" alt="image-20231130215028355" style="zoom: 50%;"></p>]]></content>
    
    
    <summary type="html">记录了SG-Former的网络结构及实验结果</summary>
    
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="图像分割" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>Transformation</title>
    <link href="https://wangak.cc/posts/ac17f787.html"/>
    <id>https://wangak.cc/posts/ac17f787.html</id>
    <published>2023-11-25T16:00:00.000Z</published>
    <updated>2023-11-26T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h2><h3 id="1-2D变换"><a href="#1-2D变换" class="headerlink" title="1. 2D变换"></a>1. 2D变换</h3><p><img src="https://typoraimg.wangak.cc/2023/img/202311271207409.png" alt="image-20231126190707151" style="zoom:50%;"></p><h4 id="1-1-缩放-scaling"><a href="#1-1-缩放-scaling" class="headerlink" title="1.1 缩放(scaling)"></a>1.1 缩放(scaling)</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202311271207653.png" alt="image-20231126190747793" style="zoom:50%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271207767.png" alt="image-20231126190853847" style="zoom: 50%;"></p><h4 id="1-2-镜像变换"><a href="#1-2-镜像变换" class="headerlink" title="1.2 镜像变换"></a>1.2 镜像变换</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202311271207557.png" alt="image-20231126191121990" style="zoom:50%;"></p><h4 id="1-3-切变（Shear-Matrix）"><a href="#1-3-切变（Shear-Matrix）" class="headerlink" title="1.3 切变（Shear Matrix）"></a>1.3 切变（Shear Matrix）</h4><p>如下图，变换过程中y坐标始终不变</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271207966.png" alt="image-20231126192230389" style="zoom:50%;"></p><h4 id="1-4-旋转-Rotate"><a href="#1-4-旋转-Rotate" class="headerlink" title="1.4 旋转(Rotate)"></a>1.4 旋转(Rotate)</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202311271208542.png" alt="image-20231126192327264" style="zoom:50%;"></p><h4 id="1-5-齐次坐标"><a href="#1-5-齐次坐标" class="headerlink" title="1.5 齐次坐标"></a>1.5 齐次坐标</h4><p><strong>平移：</strong><br><img src="https://typoraimg.wangak.cc/2023/img/202311271208287.png" alt="image-20231126193641073" style="zoom:50%;"></p><p><strong>为了表示平移操作引入了第三维坐标：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271208639.png" alt="image-20231126193653818" style="zoom:50%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271208486.png" alt="image-20231126193714639" style="zoom:50%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271208369.png" alt="image-20231126193731535" style="zoom:50%;"></p><p><em>注：<strong>point+point</strong>的结果为两个点的中点</em></p><p><strong>仿射变换的两种形式：</strong><br><img src="https://typoraimg.wangak.cc/2023/img/202311271208436.png" alt="image-20231126194003729" style="zoom:50%;"></p><p><em>注：齐次坐标变换矩阵中的a,b,c,d与线性变换中的变换矩阵是对应的</em></p><h4 id="1-6-逆变换"><a href="#1-6-逆变换" class="headerlink" title="1.6 逆变换"></a>1.6 逆变换</h4><p><strong>逆变换：</strong>变换矩阵为原变换的逆矩阵</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271208337.png" alt="image-20231126194715152" style="zoom:50%;"></p><h3 id="2-3D变换"><a href="#2-3D变换" class="headerlink" title="2. 3D变换"></a>2. 3D变换</h3><p><img src="https://typoraimg.wangak.cc/2023/img/202311271208498.png" alt="image-20231126195736702" style="zoom:50%;"></p><h4 id="2-1-仿射变换"><a href="#2-1-仿射变换" class="headerlink" title="2.1 仿射变换"></a>2.1 仿射变换</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202311271208171.png" alt="image-20231126195828157" style="zoom:50%;"></p><p><em>注：该表示方法是先做线性变换，然后再平移</em></p><h4 id="2-2-旋转"><a href="#2-2-旋转" class="headerlink" title="2.2 旋转"></a>2.2 旋转</h4><ul><li><strong>在轴上</strong></li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033304.png" alt="image-20231127122527405" style="zoom:50%;"></p><ul><li><p><strong>一般的旋转</strong>：可以将任意的旋转分为在三个轴上的旋转，其中在三个轴上的旋转角度称为欧拉角</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033703.png" alt="image-20231127122758750" style="zoom:50%;"></p></li></ul><p>​    <strong>罗德里格斯公式(Rodrigues’ Rotation Formula):</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033828.png" alt="image-20231127123545604"></p><p>注：四元数的应用</p><h3 id="2-3-视图-相机变换（View-Camera-Transformation）"><a href="#2-3-视图-相机变换（View-Camera-Transformation）" class="headerlink" title="2.3 视图/相机变换（View / Camera Transformation）"></a>2.3 视图/相机变换（View / Camera Transformation）</h3><p><strong>相机的参数：</strong>初始位置、观看角度（向量）、竖直角度（向量）</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033677.png" alt="image-20231127125538822"></p><p><strong>标准化：</strong>观看位置为原点、观看角度为-Z、向上方向为Y</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033142.png" alt="image-20231127125835234" style="zoom:50%;"></p><p>变换的方法：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033832.png" alt="image-20231127125907343" style="zoom:50%;"></p><p>由于正向变换比较复杂，考虑<strong>通过其逆矩阵来实现</strong>：R为旋转变换矩阵、T为平移变换矩阵、M为整个过程的变换矩阵</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033482.png" alt="image-20231127130030303" style="zoom:50%;"></p><p><em>注：旋转矩阵为正交矩阵，逆矩阵即是其转置</em></p><p><em>注：视图变换变换的是相机，其他的物体随着相机一起变换</em></p><h3 id="3-投影变换"><a href="#3-投影变换" class="headerlink" title="3 投影变换"></a>3 投影变换</h3><h4 id="3-1-正交投影变换"><a href="#3-1-正交投影变换" class="headerlink" title="3.1 正交投影变换"></a>3.1 正交投影变换</h4><p><strong>正交投影变换：</strong>平移+压缩</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033623.png" alt="image-20231127131958838" style="zoom:50%;"></p><p><em>注：l,r为x轴上的距离，b,t为y轴上的距离</em></p><h4 id="3-2-透视投影变换"><a href="#3-2-透视投影变换" class="headerlink" title="3.2 透视投影变换"></a>3.2 透视投影变换</h4><p>透视投影类似人眼所看东西的方式，遵循近大远小,平行线也会变得不平行</p><p><strong>用正交变换表示透视投影变换：</strong><script type="math/tex">M_{ortho}M_{persp->ortho}</script></p><p>将透视变换压成投影<script type="math/tex">M_{persp->ortho}</script></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033023.png" alt="image-20231127212210693" style="zoom:50%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033371.png" alt="image-20231127212333846" style="zoom:50%;"></p><p><em>注：其中n是近平面，f是远平面，在公式推导的过程中是<strong>默认n、f</strong>均为负数</em></p><p>因而透视投影矩阵为：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311301248538.png" alt="image-20231130123159569" style="zoom: 67%;"></p><p>又当投影接口的参数是张角fov，横纵比为aspect，近平面到原点的距离为near,远平面到原点的距离为far</p><p>由于长方体视窗体是轴对称，故有l=−r,b=−t,从原点看向−z方向看去，有n=−near,f=−far<br>                                                                    <img src="https://typoraimg.wangak.cc/2023/img/202311301247698.png" alt="image-20231130124140613" style="zoom: 67%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311301248703.png" alt="image-20231130124220304" style="zoom:67%;"></p><p>所以透视投影矩阵可化简为：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311301248469.png" alt="image-20231130124301880" style="zoom: 67%;"></p><h3 id="4-视口变换"><a href="#4-视口变换" class="headerlink" title="4.视口变换"></a>4.视口变换</h3><p><strong>视口变换</strong>用于将标准平面映射到屏幕的分辨率范围之内（缩放+平移），变换矩阵如下：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033944.png" alt="image-20231128150643474" style="zoom:50%;"></p><h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h3><p>将虚拟世界中以(x,y,z)为坐标的物体变换到以一个个像素位置(x,y) 来表示的屏幕坐标系之中(2维)的步骤：</p><ul><li><strong>模型变换(modeling tranformation)：</strong>这一步的目的是将虚拟世界中或者更具体点，游戏场景中的物体调整至他们应该在的位置</li><li><strong>摄像机变换(camera tranformation)：</strong>在游戏中我们真正在乎的是摄像机(或者说眼睛)所看到的东西，也就是需要得到物体与摄像机的相对位置</li><li><strong>投影变换(projection tranformation)：</strong>根据摄像机变换得到了所有可视范围内的物体对于摄像机的相对位置坐标(x,y,z)之后，便是根据是平行投影还是透视投影，将三维空间投影至标准二维平面([-1,1]^2)之上 （tips：这里的z并没有丢掉，为了之后的遮挡关系检测）</li><li><strong>视口变换(viewport transformation)：</strong>将处于标准平面映射到屏幕分辨率范围之内，即[-1,1]^2→[0,width]*[0,height], 其中width和height指屏幕分辨率大小</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Transformation&quot;&gt;&lt;a href=&quot;#Transformation&quot; class=&quot;headerlink&quot; title=&quot;Transformation&quot;&gt;&lt;/a&gt;Transformation&lt;/h2&gt;&lt;h3 id=&quot;1-2D变换&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>光栅化及深度测试</title>
    <link href="https://wangak.cc/posts/499d8707.html"/>
    <id>https://wangak.cc/posts/499d8707.html</id>
    <published>2023-11-25T16:00:00.000Z</published>
    <updated>2023-11-28T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="光栅化"><a href="#光栅化" class="headerlink" title="光栅化"></a>光栅化</h2><p><strong>光栅化（Rasterization）</strong>是图形学中一种常用的渲染技术，用于将三维场景中的图形对象转换为二维像素表示，以便在计算机屏幕上显示，即将图形对象（通常是三角形）映射到屏幕上的像素格子，并确定每个像素的颜色值。</p><p><strong>选择三角形作为渲染的基本图元的原因：</strong></p><ul><li>因为三角形是最简单的几何形状之一，任意三个点可以确定一个平面上的三角形</li><li><p>任意多边形都可以被分解为若干个三角形，这种分解使得处理复杂的多边形图形变得更加容易。</p></li><li><p>三角形在仿射变换下保持平面性，对三角形的变换相对简单，而不会引入复杂的扭曲。</p></li></ul><h3 id="1-直线光栅化算法"><a href="#1-直线光栅化算法" class="headerlink" title="1.直线光栅化算法"></a>1.直线光栅化算法</h3><h4 id="1-1-DDA数值微分算法"><a href="#1-1-DDA数值微分算法" class="headerlink" title="1.1 DDA数值微分算法"></a>1.1 DDA数值微分算法</h4><p>通过两点确定一条直线的斜率（k)，若|k|&lt;=1,选择x方向作为步长（选择变换快的方向），若|k|&gt;1,选择y方向作为步长。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282033642.png" alt="image-20231128195221236" style="zoom:50%;"></p><p>注：在所选的步长方向上，从起始点 <code>(x0, y0)</code> 开始，计算每个下一个点的坐标 <code>(xi, yi)</code>。对于x方向的步长，使用 <code>xi+1 = xi + 1</code>；对于 y 方向的步长，使用 <code>yi+1 = yi + m</code>。(y的结果要四舍五入)</p><h4 id="1-2-Bresenham直线绘制算法"><a href="#1-2-Bresenham直线绘制算法" class="headerlink" title="1.2 Bresenham直线绘制算法"></a>1.2 Bresenham直线绘制算法</h4><p>Bresenham直线绘制算法通过在每个步骤中选择最接近理想路径上的点来逐步绘制线段，从而避免了使用浮点数运算，提高了计算效率。</p><p><strong>pass</strong></p><h3 id="2-三角形光栅化算法"><a href="#2-三角形光栅化算法" class="headerlink" title="2.三角形光栅化算法"></a>2.三角形光栅化算法</h3><p><strong>每一个像素进行采样:</strong>判断像素中心是否在三角形内部</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034020.png" alt="image-20231128200407428" style="zoom: 50%;"></p><p><strong>判断一个点在三角形内部的方法：</strong>利用叉乘的性质</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034363.png" alt="image-20231128200536862" style="zoom:50%;"></p><p>​        分别计算 $P_0P_1×P_0Q、 P_1P_2×P_1Q、P_2P_0×P_2Q$，如果三者同号则代表点P在三条线段的同一边，那么必然处于三角形内部，如果不同号则代表该点一定在三角形外部<br><strong>利用bouding box减少点的计算：</strong>三角形通常只占屏幕很小的一部分，只对该bounding box内的点进行采样测试</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034364.png" alt="image-20231128201223186" style="zoom:50%;"></p><p><strong>锯齿现象：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034128.png" alt="image-20231128201443202" style="zoom:50%;"></p><p>产生的原因：只用了有限的采样点去逼近连续的三角形</p><h3 id="3-解决走样的方法"><a href="#3-解决走样的方法" class="headerlink" title="3.解决走样的方法"></a>3.解决走样的方法</h3><h4 id="3-1超采样反走样-Super-Sampling-AA"><a href="#3-1超采样反走样-Super-Sampling-AA" class="headerlink" title="3.1超采样反走样(Super Sampling AA)"></a>3.1超采样反走样(Super Sampling AA)</h4><p>用更多的采样点去逼近连续的三角形</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034872.png" alt="image-20231128201847832" style="zoom:50%;"></p><p>对着四个采样点分别计算颜色值，将这四个点的采样点的颜色值取均值，如下：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034448.png" alt="image-20231128202001340" style="zoom:50%;"></p><p><em>注：超采样的缺点是对计算资源的更高要求</em></p><h4 id="3-2多采样反走样-Multi-Sampling-AA"><a href="#3-2多采样反走样-Multi-Sampling-AA" class="headerlink" title="3.2多采样反走样(Multi-Sampling AA)"></a>3.2多采样反走样(Multi-Sampling AA)</h4><p>MSAA是对SSAA的改进，不再为每个采样点都计算颜色值，而只计算像素中采样点被覆盖的比例，而后在中心点处计算颜色值。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034470.png" alt="image-20231128202605057" style="zoom:50%;"></p><h4 id="3-3-先模糊（滤波），再采样"><a href="#3-3-先模糊（滤波），再采样" class="headerlink" title="3.3 先模糊（滤波），再采样"></a>3.3 先模糊（滤波），再采样</h4><p>通过在采样前进行滤波，可以去除信号中的高频分量，从而在采样时避免混叠效应，减少走样。</p><p>在频域中限制高频成分的影响，有助于避免走样问题</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311282034171.png" alt="image-20231128203246227" style="zoom:50%;"></p><h3 id="4-深度测试"><a href="#4-深度测试" class="headerlink" title="4.深度测试"></a>4.深度测试</h3><p>深度测试是指在渲染图像时确定像素的深度值（或称为Z值）以确定哪些像素应该显示在屏幕上。</p><p><em>注：深度测试是一种解决图形学中遮挡关系的技术，确保在屏幕上只显示最前面的像素，而将被遮挡的像素隐藏起来，从而呈现出正确的三维场景。</em></p><h4 id="Z-Buffer（深度缓冲）算法"><a href="#Z-Buffer（深度缓冲）算法" class="headerlink" title="Z-Buffer（深度缓冲）算法"></a>Z-Buffer（深度缓冲）算法</h4><p><strong>算法的基本思想：</strong>每个采样点（像素）存储当前的最小深度值，假设深度值（z值）始终为正值。如果一个像素的深度值较小，表示它离观察者更近；反之，如果深度值较大，则表示它离观察者更远。<strong>帧缓冲用于存储屏幕上每个像素的颜色信息，深度缓冲专门用于存储每个像素的深度值</strong>，如果当前像素的深度值较小（即更接近观察者），则更新深度缓冲和帧缓冲中的值；否则，将其视为被遮挡，不进行更新。</p><p>伪代码如下:</p><p><img src="https://typoraimg.wangak.cc/2023/img/202312011217448.png" alt="image-20231130085326419" style="zoom:50%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202312011217183.png" alt="image-20231130085351796" style="zoom:50%;"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;光栅化&quot;&gt;&lt;a href=&quot;#光栅化&quot; class=&quot;headerlink&quot; title=&quot;光栅化&quot;&gt;&lt;/a&gt;光栅化&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;光栅化（Rasterization）&lt;/strong&gt;是图形学中一种常用的渲染技术，用于将三维场景中的图形对象转换为</summary>
      
    
    
    
    <category term="图形学" scheme="https://wangak.cc/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>智能指针</title>
    <link href="https://wangak.cc/posts/38a918c7.html"/>
    <id>https://wangak.cc/posts/38a918c7.html</id>
    <published>2023-11-25T16:00:00.000Z</published>
    <updated>2023-09-26T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="智能指针"><a href="#智能指针" class="headerlink" title="智能指针"></a>智能指针</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h3><p>C++中的指针：</p><ul><li>原始指针</li><li>智能指针</li></ul><p>智能指针是原始指针的封装，其优点是会自动分配内存，不用担心潜在的内存泄露</p><p><em>注：智能指针只解决了独占/共享所有权指针的释放、传输，没有从根本上解决C++内存安全问题，不加以注意依然会造成内存安全问题</em></p><h3 id="2-独占指针：unique-ptr"><a href="#2-独占指针：unique-ptr" class="headerlink" title="2.独占指针：unique_ptr"></a>2.独占指针：unique_ptr</h3><p><strong>unique_ptr:</strong>在任何给定的时刻，只能有一个指针管理内存，当指针超出作用域时，内存将自动释放</p><p><em>注:该类型的指针不可Copy,只可以Move</em></p><p><strong>unique_ptr的三种创建方式：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;memory&gt;</span><br><span class="line">#include &quot;cat.h&quot;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[]) &#123;</span><br><span class="line">    // 1.栈</span><br><span class="line">    // 对象是在栈上创建的(而不是使用 new 操作符在堆上分配对象）,那么在对象的作用域结束时，其析构函数会被自动调用。</span><br><span class="line">    Cat c1(&quot;OK&quot;);</span><br><span class="line">    c1.cat_info();</span><br><span class="line">    &#123;</span><br><span class="line">        Cat c2(&quot;OK&quot;);</span><br><span class="line">        c2.cat_info();</span><br><span class="line">    &#125; // 在这个代码块结束时，c2 对象将被销毁，调用析构函数</span><br><span class="line"> </span><br><span class="line">    // 2.堆</span><br><span class="line">    //2.1 原始指针（不安全）</span><br><span class="line">    Cat *c_p1=new Cat(&quot;yy&quot;);</span><br><span class="line">    c_p1-&gt;cat_info();</span><br><span class="line">    &#123;</span><br><span class="line">        Cat *c_p1=new Cat(&quot;yy&quot;);</span><br><span class="line">        c_p1-&gt;cat_info();</span><br><span class="line">        delete c_p1;//原始指针不会自动调用析构函数，要使用delete方法</span><br><span class="line">    &#125;</span><br><span class="line">    delete c_p1;</span><br><span class="line">    // 2.2 智能指针</span><br><span class="line">    // 2.2.3 unique_pointer的三种创建方式</span><br><span class="line">    // 2.2.3.1 第一种方式</span><br><span class="line">    Cat *c_p2=new Cat(&quot;ok&quot;);</span><br><span class="line">    unique_ptr&lt;Cat&gt; u_c_p2&#123;c_p2&#125;;</span><br><span class="line">    c_p2=nullptr;//原始指针一般需要置空，否则其还能使用</span><br><span class="line">    u_c_p2-&gt;cat_info();</span><br><span class="line">    // 2.2.3.2 第二种方式</span><br><span class="line">    unique_ptr&lt;Cat&gt; u_c_p3&#123;new Cat(&quot;dd&quot;)&#125;;</span><br><span class="line">    u_c_p3-&gt;cat_info();</span><br><span class="line">    // 2.2.3.2 第三种方式（推荐）</span><br><span class="line">    unique_ptr&lt;Cat&gt; u_c_p4=make_unique&lt;Cat&gt;(&quot;ook&quot;);</span><br><span class="line">    u_c_p4-&gt;cat_info();</span><br><span class="line">    std::cout &lt;&lt; &quot;-----yz ------&quot; &lt;&lt; std::endl;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;智能指针&quot;&gt;&lt;a href=&quot;#智能指针&quot; class=&quot;headerlink&quot; title=&quot;智能指针&quot;&gt;&lt;/a&gt;智能指针&lt;/h2&gt;&lt;h3 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1.概述&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="C++" scheme="https://wangak.cc/categories/C/"/>
    
    
    <category term="C++" scheme="https://wangak.cc/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>SPM</title>
    <link href="https://wangak.cc/posts/236d2982.html"/>
    <id>https://wangak.cc/posts/236d2982.html</id>
    <published>2023-11-18T06:23:40.209Z</published>
    <updated>2023-11-28T12:35:31.360Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SPM"><a href="#SPM" class="headerlink" title="SPM"></a>SPM</h2><p><strong>论文：《Learning with Explicit Shape Priors for Medical Image Segmentation》（TMI 2023)</strong></p><p><strong>探索形状先验(shape priors)对分割性能的影响</strong></p><p>基于unet的医学图像分割模型的局限性:cnn的感受野有限，无法利用器官或组织之间的远距离和全局空间关系，无法实现精细的形状表示。（注意力模块扩大模型的感受野，隐式地捕获形状信息）</p><p><em>注：通过设计特定的损失函数，而不是Dice损失或交叉熵损失，将明确的形状先验集成到分割框架中。但这些损失函数是特定于任务的，不能很容易地扩展到不同的数据集</em></p><p>提出了显式形状模型（SPM），以形状先验作为额外的输入来增强模型的形状表示能力。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436431.png" alt="image-20231120152537182" style="zoom:67%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436712.png" alt="image-20231120163304452" style="zoom:67%;"></p><p>其中F代表模型的前向传播，S代表构造图像I和标签L之间映射的形状先验。</p><p><strong>注意力图：</strong>生成的形状先验在推断阶段充当了注意力图，用于定位感兴趣的区域，并抑制背景区域</p><p><strong>SPM模块：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436670.png" alt="image-20231120153357914" style="zoom:67%;"></p><p>SPM模块由the self-update block (SUB)、cross-update block (CUB)</p><p><strong>the self-update block (SUB)：</strong>以形状先验作为输入，用于生成全局形状先验</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436041.png" alt="image-20231120154358605" style="zoom:50%;"></p><p>SUB的结构缺乏对局部视觉结构的建模，全局形状先验不具有精确的形状和轮廓信息。</p><p><strong>cross-update block (CUB)：</strong>建模局部形状先验</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436616.png" alt="image-20231120160130787" style="zoom: 50%;"></p><p><script type="math/tex">C_{map}</script>:一个C × N矩阵,用于评估C通道特征映射Fo和N通道形状先验之间的关系。</p><p>下采样<script type="math/tex">F_e</script>生成局部形状先验<script type="math/tex">S_L</script>:</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436429.png" alt="image-20231120160808202" style="zoom:50%;"></p><p>增强的形状先验融合了SUB生成全局形状先验及CUB生成的局部形状先验</p><h3 id="实验部分："><a href="#实验部分：" class="headerlink" title="实验部分："></a>实验部分：</h3><p><strong>与其他方法的对比：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436022.png" alt="image-20231120202559717" style="zoom: 67%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436614.png" alt="image-20231120202723390" style="zoom: 67%;"></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436085.png" alt="image-20231120202732327" style="zoom: 67%;"></p><p><strong>消融实验：</strong>在BRATS 2020（脑肿瘤）、<strong>VerSe2019</strong>(脊柱)、ACDC（心脏）</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311271436828.png" alt="image-20231120201045294" style="zoom: 80%;"></p><p>表明SPM有增强模型对相对规则的形状区域的表示能力</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;SPM&quot;&gt;&lt;a href=&quot;#SPM&quot; class=&quot;headerlink&quot; title=&quot;SPM&quot;&gt;&lt;/a&gt;SPM&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;论文：《Learning with Explicit Shape Priors for Medical Image </summary>
      
    
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="图像分割" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>MedNeXt</title>
    <link href="https://wangak.cc/posts/9ce6c01f.html"/>
    <id>https://wangak.cc/posts/9ce6c01f.html</id>
    <published>2023-11-12T16:00:00.000Z</published>
    <updated>2023-11-12T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MedNeXt-Transformer-driven-Scaling-of-ConvNets-for-Medical-Image-Segmentation"><a href="#MedNeXt-Transformer-driven-Scaling-of-ConvNets-for-Medical-Image-Segmentation" class="headerlink" title="MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation"></a>MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation</h2><p><strong>论文：《MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation》(MICCAI 2023)</strong></p><h3 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1.网络结构"></a>1.网络结构</h3><p><img src="https://typoraimg.wangak.cc/2023/img/202311130851990.png" alt="image-20231108195751803"></p><p><strong>MedNeXt Block:</strong></p><ul><li><p>深度卷积层（DW）：k × k × k的深度卷积，归一化使用channel-wise GroupNorm</p></li><li><p>Expansion Layer:较大的 R 值允许网络在宽度方向上扩展，而 1×1×1 核限制了计算量</p></li><li><p>Compression Layer:1×1×1卷积层对输出通道进行压缩</p></li></ul><p><strong>MedNeXt Down Block和MedNeXt Up Block：</strong></p><ul><li>添加了一个残差连接1×1×1卷积或转置卷积，步幅为2</li></ul><p>​    解码器层使用<strong>深度监督</strong>，在较低分辨率下具有较低的损失权值（深度监督：在网络的中间部分添加了额外的loss，不同位置的loss按系数求和。深度监督的目的是为了浅层能够得到更加充分的训练，解决深度神经网络训练梯度消失和收敛速度过慢等问题。）</p><p><strong>UpKern 初始化：</strong></p><p>大卷积核的缺陷：大卷积核性能可能更容易达到一个瓶颈，无法再进一步提高。(大卷积核模型有更多的参数，因此更容易过拟合训练数据)</p><p>医学图像分割任务的数据少之又少，性能更容易饱和。</p><p>为了帮助大卷积核网络在医学图像分割等任务中更好地利用有限数据，从而改善性能。</p><p>对预训练小核网络进行三线性上采样来初始化大核网络，从而<strong>迭代地增加核大小</strong>。其他的大小相同的层（包括归一化层）都通过直接复制预训练层的权重来初始化。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311130851317.png" alt="image-20231108204926791" style="zoom:67%;"></p><p><strong>MedNeXt四种配置及消融实验：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311130851800.png" alt="image-20231108211021855"></p><p>通道数（C)均设置为32</p><ul><li>在重采样时保留了特征映射中的语义丰富性</li><li>没有UpKern的大内核和小内核的性能是没有区别的</li><li>大卷积核中的性能提升是由于UpKern与大卷积核的结合，而不仅仅是更长的训练</li></ul><h3 id="2-实验结果"><a href="#2-实验结果" class="headerlink" title="2.实验结果"></a>2.实验结果</h3><p><img src="https://typoraimg.wangak.cc/2023/img/202311130851293.png" alt="image-20231108214400563"></p>]]></content>
    
    
    <summary type="html">记录了MedNeXt的网络结构及实验结果</summary>
    
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="图像分割" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>C++编程出现的错误及解决</title>
    <link href="https://wangak.cc/posts/f3261b08.html"/>
    <id>https://wangak.cc/posts/f3261b08.html</id>
    <published>2023-11-11T07:07:32.208Z</published>
    <updated>2023-11-11T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="C-编程出现的错误及解决"><a href="#C-编程出现的错误及解决" class="headerlink" title="C++编程出现的错误及解决"></a>C++编程出现的错误及解决</h2><h3 id="1-Undefined-reference"><a href="#1-Undefined-reference" class="headerlink" title="1.Undefined reference"></a>1.Undefined reference</h3><p><strong>1.1目标文件未正确链接:</strong></p><p><strong>原因：</strong>有多个源文件，会独立编译它们,会导致对象没有正确链</p><p><strong>解决方法：同时编译这两个文件</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g++ cat.cpp test.cpp -o test//同时编译cat.cpp和test.cpp，并生成可执行文件test</span><br><span class="line">./test  //运行test.exe</span><br></pre></td></tr></table></figure><p>注：有多个源文件时使用如下指令进行编译</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g++ *.cpp -o main</span><br><span class="line">./main</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;C-编程出现的错误及解决&quot;&gt;&lt;a href=&quot;#C-编程出现的错误及解决&quot; class=&quot;headerlink&quot; title=&quot;C++编程出现的错误及解决&quot;&gt;&lt;/a&gt;C++编程出现的错误及解决&lt;/h2&gt;&lt;h3 id=&quot;1-Undefined-reference&quot;&gt;</summary>
      
    
    
    
    <category term="C++" scheme="https://wangak.cc/categories/C/"/>
    
    
    <category term="C++" scheme="https://wangak.cc/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>nnUNet v2模型训练</title>
    <link href="https://wangak.cc/posts/4a35a285.html"/>
    <id>https://wangak.cc/posts/4a35a285.html</id>
    <published>2023-11-06T16:00:00.000Z</published>
    <updated>2023-11-06T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="nnUNet-v2模型训练"><a href="#nnUNet-v2模型训练" class="headerlink" title="nnUNet v2模型训练"></a>nnUNet v2模型训练</h2><h3 id="1-数据集处理"><a href="#1-数据集处理" class="headerlink" title="1.数据集处理"></a>1.数据集处理</h3><p><strong>nnUnet要求rgb-png格式的数据</strong>，故将原数据集由单通道堆叠成三通道的RGB图像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">def gray_to_rgb(image_gray):</span><br><span class="line">    # 创建一个全零的三通道图像</span><br><span class="line">    height, width = image_gray.shape</span><br><span class="line">    image_rgb = np.zeros((height, width, 3), dtype=np.uint8)</span><br><span class="line">    # 将灰度图像的值复制到红通道</span><br><span class="line">    image_rgb[:, :, 2] = image_gray</span><br><span class="line">    image_rgb[:, :, 1] = image_gray</span><br><span class="line">    image_rgb[:, :, 0] = image_gray</span><br><span class="line">    return image_rgb</span><br><span class="line"># 设置目标文件夹路径</span><br><span class="line"> # 包含灰度PNG图像的文件夹路径</span><br><span class="line">output_folder = # 用于保存RGB图像的文件夹路径</span><br><span class="line">root_folder=</span><br><span class="line"># 创建输出文件夹（如果不存在）</span><br><span class="line">if not os.path.exists(output_folder):</span><br><span class="line">    os.makedirs(output_folder)</span><br><span class="line">for root, dirs, files in os.walk(root_folder):</span><br><span class="line">    # 遍历目标文件夹中的所有图像文件</span><br><span class="line">    if root == root_folder:</span><br><span class="line">        for dir_name in dirs:</span><br><span class="line">            input_folder = os.path.join(root, dir_name, dir_name + &quot;_label&quot;)</span><br><span class="line">            print(input_folder)</span><br><span class="line">            for filename in os.listdir(input_folder):</span><br><span class="line">                if filename.endswith(&#x27;.png&#x27;):</span><br><span class="line">                    # 构造图像文件的完整输入路径</span><br><span class="line">                    input_image_path = os.path.join(input_folder, filename)</span><br><span class="line">                    # 读取灰度图像</span><br><span class="line">                    image_gray = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">                    if image_gray is not None:</span><br><span class="line">                        # 转换为RGB图像</span><br><span class="line">                        image_rgb = gray_to_rgb(image_gray)</span><br><span class="line">                        # 构造保存的RGB图像文件名（输出路径）</span><br><span class="line">                        output_image_path = os.path.join(output_folder, filename.replace(&#x27;.png&#x27;, &#x27;_rgb.png&#x27;))</span><br><span class="line">                        # 保存RGB图像到指定输出路径</span><br><span class="line">                        cv2.imwrite(output_image_path, image_rgb)</span><br><span class="line">            print(&quot;Conversion completed.&quot;)</span><br></pre></td></tr></table></figure><p><strong>原先数据集的格式要求：</strong></p><ul><li><strong>train</strong><ul><li><strong>images</strong></li><li><strong>labels</strong></li></ul></li><li><strong>test</strong><ul><li><strong>images</strong></li><li><strong>labels</strong></li></ul></li></ul><p><strong>将数据集转化为nnUnet标准格式，改写nnUNet/nnunetv2/dataset_conversion/Dataset120_RoadSegmentation.py</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # extracted archive from https://www.kaggle.com/datasets/insaff/massachusetts-roads-dataset?resource=download</span><br><span class="line">    source = &#x27;/root/autodl-tmp/nnUNet/Coronary&#x27;</span><br><span class="line">    print(source)</span><br><span class="line">    dataset_name = &#x27;Dataset150_Segmentation&#x27;</span><br><span class="line">    nnUNet_raw = &#x27;/root/autodl-tmp/nnUNet/dataset/nnUNet_raw&#x27;</span><br><span class="line">    imagestr = join(nnUNet_raw, dataset_name, &#x27;imagesTr&#x27;)</span><br><span class="line">    imagests = join(nnUNet_raw, dataset_name, &#x27;imagesTs&#x27;)</span><br><span class="line">    labelstr = join(nnUNet_raw, dataset_name, &#x27;labelsTr&#x27;)</span><br><span class="line">    labelsts = join(nnUNet_raw, dataset_name, &#x27;labelsTs&#x27;)</span><br><span class="line">   </span><br><span class="line">    maybe_mkdir_p(imagestr)</span><br><span class="line">    maybe_mkdir_p(imagests)</span><br><span class="line">    maybe_mkdir_p(labelstr)</span><br><span class="line">    maybe_mkdir_p(labelsts)</span><br><span class="line"></span><br><span class="line">    train_source = join(source, &#x27;train&#x27;)</span><br><span class="line">    test_source = join(source, &#x27;test&#x27;)</span><br><span class="line"></span><br><span class="line">    with multiprocessing.get_context(&quot;spawn&quot;).Pool(8) as p:</span><br><span class="line"></span><br><span class="line">        # not all training images have a segmentation</span><br><span class="line">        valid_ids = subfiles(join(train_source, &#x27;labels&#x27;), join=False, suffix=&#x27;png&#x27;)</span><br><span class="line">        num_train = len(valid_ids)</span><br><span class="line">        r = []</span><br><span class="line">        for v in valid_ids:</span><br><span class="line">            r.append(</span><br><span class="line">                p.starmap_async(</span><br><span class="line">                    load_and_covnert_case,</span><br><span class="line">                    ((</span><br><span class="line">                         join(train_source, &#x27;images&#x27;, v),</span><br><span class="line">                         join(train_source, &#x27;labels&#x27;, v),</span><br><span class="line">                         join(imagestr, v[:-4] + &#x27;_0000.png&#x27;),</span><br><span class="line">                         join(labelstr, v),</span><br><span class="line">                         50</span><br><span class="line">                     ),)</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        # test set</span><br><span class="line">        valid_ids = subfiles(join(test_source, &#x27;labels&#x27;), join=False, suffix=&#x27;png&#x27;)</span><br><span class="line">        for v in valid_ids:</span><br><span class="line">            r.append(</span><br><span class="line">                p.starmap_async(</span><br><span class="line">                    load_and_covnert_case,</span><br><span class="line">                    ((</span><br><span class="line">                         join(test_source, &#x27;images&#x27;, v),</span><br><span class="line">                         join(test_source, &#x27;labels&#x27;, v),</span><br><span class="line">                         join(imagests, v[:-4] + &#x27;_0000.png&#x27;),</span><br><span class="line">                         join(labelsts, v),</span><br><span class="line">                         50</span><br><span class="line">                     ),)</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        _ = [i.get() for i in r]</span><br><span class="line"></span><br><span class="line">    generate_dataset_json(join(nnUNet_raw, dataset_name), &#123;0: &#x27;R&#x27;, 1: &#x27;G&#x27;, 2: &#x27;B&#x27;&#125;, &#123;&#x27;background&#x27;: 0, &#x27;coronary&#x27;: 1&#125;,</span><br><span class="line">                          num_train, &#x27;.png&#x27;, dataset_name=dataset_name)</span><br></pre></td></tr></table></figure><p><strong>生成的数据集：</strong></p><ul><li>数据集名称<ul><li>imagesTr</li><li>imagesTs</li><li>labelsTr</li><li>labelsTs</li><li>dataset.json</li></ul></li></ul><p><strong>添加环境变量：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export nnUNet_raw=&quot;/root/autodl-tmp/nnUNet/dataset/nnUNet_raw&quot;</span><br><span class="line">export nnUNet_preprocessed=&quot;/root/autodl-tmp/nnUNet/dataset/nnUNet_preprocessed&quot;</span><br><span class="line">export nnUNet_results=&quot;/root/autodl-tmp/nnUNet/dataset/nnUnet_results&quot;</span><br></pre></td></tr></table></figure><p><strong>预处理数据集：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nnUNetv2_plan_and_preprocess -d 150 --verify_dataset_integrity #150为任务id</span><br></pre></td></tr></table></figure><h3 id="2-模型训练"><a href="#2-模型训练" class="headerlink" title="2.模型训练"></a>2.模型训练</h3><p><strong>开始训练：</strong></p><p><code>nnUNetv2_train CONFIGURATION TRAINER_CLASS_NAME TASK_NAME_OR_ID FOLD (additional options)</code></p><ul><li><code>CONFIGURATION：</code> 模型架构，三种Unet: 2D U-Net, 3D U-Net and a U-Net Cascade(U-Net级联)。</li><li><code>TASK_NAME_OR_ID：</code> 任务全名TaskXXX_MYTASK或者是ID号</li><li><code>FOLD：</code> 第几折交叉验证，可选 [0, 1, 2, 3, 4]，一共五折。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nnUNetv2_train 666 2d 4</span><br></pre></td></tr></table></figure><p><strong>loss曲线：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311062115385.png" alt="image-20231106164804089" style="zoom: 67%;"></p><h3 id="3-模型测试"><a href="#3-模型测试" class="headerlink" title="3.模型测试"></a>3.模型测试</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nnUNetv2_predict -i “测试集路径” -o “输出路径” -chk checkpoint_best.pth -c 2d -f 4 -d 150 --save_probabilities</span><br></pre></td></tr></table></figure><p>将二值掩码转换为0或255</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">def process_images_in_folder(input_folder, output_folder):</span><br><span class="line">    for root, dirs, files in os.walk(input_folder):</span><br><span class="line">        for file in files:</span><br><span class="line">            if file.endswith(&quot;.png&quot;):</span><br><span class="line">                input_image_path = os.path.join(root, file)</span><br><span class="line">                output_image_path = os.path.join(output_folder, file)</span><br><span class="line"></span><br><span class="line">                # 打开输入图像</span><br><span class="line">                image = Image.open(input_image_path)</span><br><span class="line"></span><br><span class="line">                # 将像素值为1的通道变为255</span><br><span class="line">                image = image.convert(&quot;RGB&quot;)</span><br><span class="line">                data = image.getdata()</span><br><span class="line">                new_data = [(r, g, b) if r != 1 and g != 1 and b != 1 else (255, 255, 255) for (r, g, b) in data]</span><br><span class="line">                image.putdata(new_data)</span><br><span class="line"></span><br><span class="line">                # 保存修改后的图像</span><br><span class="line">                image.save(output_image_path)</span><br><span class="line"></span><br><span class="line"># 指定输入文件夹和输出文件夹的路径</span><br><span class="line">input_folder_path = &quot;&quot;</span><br><span class="line">output_folder_path = &quot;&quot;</span><br><span class="line"></span><br><span class="line">if not os.path.exists(output_folder_path):</span><br><span class="line">    os.makedirs(output_folder_path)</span><br><span class="line"></span><br><span class="line">process_images_in_folder(input_folder_path, output_folder_path)</span><br></pre></td></tr></table></figure><p><img src="https://typoraimg.wangak.cc/2023/img/202311062116900.png" alt="image-20231106200912078"></p><p><strong>评价指标：</strong></p><p><strong>HD95: 5.20</strong></p><p><strong>Average Dice: 0.8144</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;nnUNet-v2模型训练&quot;&gt;&lt;a href=&quot;#nnUNet-v2模型训练&quot; class=&quot;headerlink&quot; title=&quot;nnUNet v2模型训练&quot;&gt;&lt;/a&gt;nnUNet v2模型训练&lt;/h2&gt;&lt;h3 id=&quot;1-数据集处理&quot;&gt;&lt;a href=&quot;#1-</summary>
      
    
    
    
    <category term="模型训练" scheme="https://wangak.cc/categories/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/"/>
    
    
    <category term="模型训练" scheme="https://wangak.cc/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>3D UX-NET</title>
    <link href="https://wangak.cc/posts/eabf9f8.html"/>
    <id>https://wangak.cc/posts/eabf9f8.html</id>
    <published>2023-11-06T16:00:00.000Z</published>
    <updated>2023-11-06T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3D-UX-NET"><a href="#3D-UX-NET" class="headerlink" title="3D UX-NET"></a>3D UX-NET</h2><p><strong>论文：《3D UX-NET: A LARGE KERNEL VOLUMETRIC CONVNET MODERNIZING HIERARCHICAL TRANSFORMER</strong><br><strong>FOR MEDICAL IMAGE SEGMENTATION》（ICLR 2023）</strong></p><h3 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1.网络结构"></a>1.网络结构</h3><p><img src="https://typoraimg.wangak.cc/2023/img/202311062115336.png" alt="image-20231106201433865"></p><p>采用具备大卷积核的投影层来提取 patch-wise 特征作为编码器的输入</p><p><strong>对Swin transformer的transformer block做了替换：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202311062115856.png" alt="image-20231106202256333" style="zoom:67%;"></p><p>使用大卷积核(7 × 7 × 7)的深度卷积来模仿Swin Transformer的局部自注意力和窗口移动。</p><p>使用2 × 2 × 2、步幅为2的标准卷积块来实现下采样</p><p>在Swin Transformer中MLP隐藏层维度比输入维度宽四倍，引入了具有 1 × 1 × 1 卷积核大小的深度卷积缩放(DCS)，以独立地线性缩放每个通道特征，减少跨通道上下文产生的冗余信息</p><p>DCS：1x1x1的深度卷积+1x1x1的分组卷积</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311062115037.png" alt="image-20231106205655475" style="zoom:67%;"></p><p>从实验中发现：使用深度卷积缩放(DCS)参数量得到了减小，效果并没有下降</p><p><img src="https://typoraimg.wangak.cc/2023/img/202311062115199.png" alt="image-20231106204002121"></p><p>编码器的输出特征由残差块作进一步的处理，以稳定提取的特征。（残差块由两个经过实例归一化的后归一化3 × 3 × 3卷积层组成）</p><p>转置卷积层实现上采样，其输出的特征与编码器的输出进行连接后，再次输入到残差块中。</p><h3 id="2-实验结果"><a href="#2-实验结果" class="headerlink" title="2.实验结果"></a>2.实验结果</h3><p><img src="https://typoraimg.wangak.cc/2023/img/202311062115341.png" alt="image-20231106210428239"></p><p>3D UX-Net 在这几个分割任务中均展示出最佳性能，并且 Dice 分数有了一定的提高</p>]]></content>
    
    
    <summary type="html">记录了3D UX-NET的网络结构及实验结果</summary>
    
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="图像分割" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>图像分割常用指标</title>
    <link href="https://wangak.cc/posts/70fa35a7.html"/>
    <id>https://wangak.cc/posts/70fa35a7.html</id>
    <published>2023-11-01T16:00:00.000Z</published>
    <updated>2023-11-01T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="图像分割常用指标"><a href="#图像分割常用指标" class="headerlink" title="图像分割常用指标"></a>图像分割常用指标</h3><h4 id="1-DSC（Dice相似系数）"><a href="#1-DSC（Dice相似系数）" class="headerlink" title="1.DSC（Dice相似系数）"></a>1.DSC（Dice相似系数）</h4><p><strong>DSC：用于衡量区域的重合程度</strong></p><p><strong>计算公式：</strong></p><script type="math/tex; mode=display">DSC = (2 * |A ∩ B|) / (|A| + |B|)</script><p>其中，A为算法生成的分割结果的像素集合，B为参考分割结果的像素集合</p><ul><li><p>DSC值范围在0到1之间，其中0表示完全不相似，1表示完全相似。</p></li><li><p>DSC值越接近1，表示算法生成的分割结果与参考分割结果越相似</p></li></ul><p><em>注：Dice相似系数仅考虑了像素的重叠情况，而没有考虑像素之间的空间关系，在存在模糊边界的分割任务中,Dice系数可能无法准确评估模型的性能。</em></p><h4 id="2-HD-豪斯多夫距离"><a href="#2-HD-豪斯多夫距离" class="headerlink" title="2.HD(豪斯多夫距离)"></a>2.HD(豪斯多夫距离)</h4><p><strong>HD:表示预测分割区域边界与真实区域边界之间的最大距离，其值越小代表预测边界分割误差越小、质量越好。</strong></p><p><strong>计算公式：</strong></p><p><img src="/posts/70fa35a7.htm/Users\wangak\AppData\Roaming\Typora\typora-user-images\image-20231102100120629.png" alt="image-20231102100120629" style="zoom:67%;"></p><p><img src="/posts/70fa35a7.htm/Users\wangak\AppData\Roaming\Typora\typora-user-images\image-20231102100057838.png" alt="image-20231102100057838" style="zoom:67%;"></p><p><strong>计算步骤：</strong></p><p>​    (1)对点集X中的每一个点x计算其到点集Y中的每一个点y的距离，保留最短距离，然后找出保留的最短距离中的最大距离记为Dxy。</p><p>​    (2)对点集Y中的每一个点y计算其到点集X中的每一个点x的距离，保留最短距离，然后找出保留最短距离中的最大距离记为Dyx。</p><p>​    (3)取Dxy和Dyx最大值作为点集X和Y之间的豪斯多夫距离。</p><p><strong>HD95(95％ 豪斯多夫距离):</strong></p><p>为了排除一些离群点造成的不合理距离，保持整体数值稳定性，一般选择从小到大排名前 95%的距离作为实际豪斯多夫距离，称之为 95% 豪斯多夫距离。</p><p><strong>注：Dice相似系数主要关注分割结果的整体准确性，HD95则更侧重于考虑分割边界的精确性</strong></p><p><strong>注： 豪斯多夫距离目标是捕捉两个集合之间的最大不一致，对于孤立的离群点或噪声非常敏感，不适用于噪声较多的图像。</strong></p><h4 id="3-ASD（平均表面距离）"><a href="#3-ASD（平均表面距离）" class="headerlink" title="3.ASD（平均表面距离）"></a>3.ASD（平均表面距离）</h4><p>平均表面距离：用来测量分割结果中的边界与真实标签中的边界之间的距离。</p><p><strong>计算分割结果中的每个像素与真实标签中的最近像素之间的距离，然后取平均值。</strong></p><p><img src="/posts/70fa35a7.htm/Users\wangak\AppData\Roaming\Typora\typora-user-images\image-20231102102746435.png" alt="image-20231102102746435" style="zoom: 50%;"></p><p><strong>ASSD(平均对称表面距离):</strong></p><p>​                                                            <script type="math/tex">\large ASSD(X,Y)={ASD(X,Y)+ASD(Y,X)}/2</script></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;图像分割常用指标&quot;&gt;&lt;a href=&quot;#图像分割常用指标&quot; class=&quot;headerlink&quot; title=&quot;图像分割常用指标&quot;&gt;&lt;/a&gt;图像分割常用指标&lt;/h3&gt;&lt;h4 id=&quot;1-DSC（Dice相似系数）&quot;&gt;&lt;a href=&quot;#1-DSC（Dice相似系数</summary>
      
    
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="图像分割" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>nnFormer</title>
    <link href="https://wangak.cc/posts/9e11ec23.html"/>
    <id>https://wangak.cc/posts/9e11ec23.html</id>
    <published>2023-10-30T16:00:00.000Z</published>
    <updated>2023-10-30T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="nnFormer"><a href="#nnFormer" class="headerlink" title="nnFormer"></a>nnFormer</h2><p><strong>论文：《nnFormer: Volumetric Medical Image Segmentation via a 3D Transformer》（TMI2022）</strong></p><h3 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1.网络结构"></a>1.网络结构</h3><p><img src="https://typoraimg.wangak.cc/2023/img/202310252011844.png" alt="image-20231025201100423" style="zoom: 80%;"></p><h4 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h4><p><strong>nnFormer的输入：</strong>对原始图像中随机裁剪（HxWxD)，数据增强技术，有助于模型更好地学习不同部分的特征。</p><p><strong>The embedding layer:</strong>（将输入数据转换成高维张量）</p><ul><li><strong>使用卷积的好处：</strong>对比transformer使用线性层对patch的向量进行映射，卷积层能够更细致地捕获图像中的像素级信息（减少了训练的参数数量，卷积核在处理特定区域时更加专注）</li><li><strong>在初始阶段使用小卷积核的连续卷积层，相对于大卷积核的好处：</strong>降低计算复杂度,同时保持相同大小的感受野(非线性激活函数多了，语义表达能力增强了)</li></ul><p><img src="https://typoraimg.wangak.cc/2023/img/202310252109346.png" alt="image-20231025210627610"></p><p><em>注：根据输入的patch大小卷积步长也会有相应的变化</em></p><p><strong>Local Volume-based Multi-head Self-attention (LV-MSA)：</strong>将不同尺度的信息和高分辨率的空间信息相互关联</p><p>不同尺度的特征由下采样层生成，高分辨率的空间信息则由嵌入层编码</p><p>使用的是一种基于局部三维图像块的self-attention计算方式（跟Swin-UNet类似)</p><p><img src="https://typoraimg.wangak.cc/2023/img/202310252129451.png" alt="image-20231025212855680" style="zoom: 80%;"></p><p><strong>SLV-MSA:</strong>是LV-MSA的shifted版本（类似于Swin-UNet，目的是使局部的三维图像块之间产生联系）</p><p><img src="https://typoraimg.wangak.cc/2023/img/202310252130572.png" alt="image-20231025213050517" style="zoom: 67%;"></p><p><em>注：$S_H、S_W、S_D$代表每个图像块中的patch的数量</em></p><p>使用LV-MSA减少了计算的复杂度，计算复杂度和图像之间是线性的关系</p><p><img src="https://typoraimg.wangak.cc/2023/img/202310252139215.png" alt="image-20231025213709821" style="zoom: 80%;"></p><p>使用相对位置偏置B来引入位置信息</p><p><strong>The down-sampling layer：</strong></p><p>与Swin-UNet使用patch merging不同，作者选择了使用简单的卷积来实现下采样，卷积下采样可以在不同空间维度上应用不同的步长，以根据问题的要求调整下采样率。（可以根据数据的特点来灵活设置，避免过度下采样，对于三维的图像在某些维度上数据切片数量有限，这时可以将该维度的步长设置为1）</p><h4 id="Bottleneck"><a href="#Bottleneck" class="headerlink" title="Bottleneck"></a>Bottleneck</h4><p>不同于编码器使用局部自注意力机制，Bottleneck中使用全局自注意力。</p><p>计算复杂度：</p><p><img src="https://typoraimg.wangak.cc/2023/img/202310271637998.png" alt="image-20231027153408838" style="zoom: 80%;"></p><p>编码器部分减小了h、w、d，这为GV-MSA的应用创造了条件，与LV-MSA相比，GV-MSA能够提供更大的感受野</p><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p><strong>上采样操作</strong>：使用转置卷积</p><p><strong>Skip Attention：</strong>（使不同层之间的信息交流变得更加灵活）</p><p><img src="https://typoraimg.wangak.cc/2023/img/202310271636161.png" alt="image-20231027155805206" style="zoom: 67%;"></p><h3 id="2-实验部分"><a href="#2-实验部分" class="headerlink" title="2.实验部分"></a>2.实验部分</h3><h4 id="与基于Transformer的方法学的比较"><a href="#与基于Transformer的方法学的比较" class="headerlink" title="与基于Transformer的方法学的比较"></a>与基于Transformer的方法学的比较</h4><p><strong>脑肿瘤分割</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202310271636932.png" alt="image-20231027162254249" style="zoom: 67%;"></p><p>列出了所有模型在脑瘤分割任务上的实验结果,nnFormer在所有类别中取得了最低的HD95和最高的DSC分数。</p><p><strong>多器官分割（Synapse）</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202310302100261.png" alt="image-20231029163515666"></p><p>与以前基于Transformer的方法相比，nnFormer在分割胰腺(Pancreas)和胃(Stomach)方面更有优势</p><p><strong>与nnUNet的比较</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202310302100944.png" alt="image-20231030203836841"></p><p>nnFormer的HD95似乎更有优势，其可以更好地划分对象边界。</p><p>nnAvg：对nnFormer和nnUNet的预测结果进行平均化，发现整体的性能得到了提高，表明nnFormer和nnUNet是可以互补的。</p><h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202310302100685.png" alt="image-20231030205355146"></p><ul><li><p>嵌入层使用小卷积核大小的连续卷积层</p></li><li><p>卷积下采样层替换掉了patch Merging层</p></li><li><p>GV-MSA替换了Bottleneck的LV-MSA</p></li><li><p>Skip Attention代替跳跃连接</p></li><li>SLV-MSA层与LV-MSA层级联，全局自注意力层的数量增加一倍</li></ul>]]></content>
    
    
    <summary type="html">记录了nnFormer的网络结构及实验结果</summary>
    
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="图像分割" scheme="https://wangak.cc/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>File类</title>
    <link href="https://wangak.cc/posts/c8b66f0a.html"/>
    <id>https://wangak.cc/posts/c8b66f0a.html</id>
    <published>2023-10-18T12:44:09.000Z</published>
    <updated>2023-11-26T02:41:35.878Z</updated>
    
    <content type="html"><![CDATA[<h2 id="File类"><a href="#File类" class="headerlink" title="File类"></a>File类</h2><h3 id="1-创建File类的对象"><a href="#1-创建File类的对象" class="headerlink" title="1.创建File类的对象"></a>1.创建File类的对象</h3><p><img src="https://typoraimg.wangak.cc/2023/img/1.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//创建一个File对象，指向某个具体的文件</span><br><span class="line">      File f1=new File(&quot;./data/test.txt&quot;);</span><br><span class="line">      System.out.println(f1.length());//文件大小</span><br><span class="line"></span><br><span class="line">      File f2=new File(&quot;./data/aaa.txt&quot;);//File对象可以指向空路径</span><br><span class="line">      System.out.println(f2.length());//0</span><br><span class="line">      System.out.println(f2.exists());//false</span><br></pre></td></tr></table></figure><h3 id="2-判断文件类型、获取文件信息"><a href="#2-判断文件类型、获取文件信息" class="headerlink" title="2.判断文件类型、获取文件信息"></a>2.判断文件类型、获取文件信息</h3><p><img src="https://typoraimg.wangak.cc/2023/img/2.png" alt="img" style="zoom: 50%;"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">//1.创建一个File对象，指向某个具体的文件</span><br><span class="line">      File f1=new File(&quot;./data/test.txt&quot;);</span><br><span class="line">      //2.判断文件路径是否存在</span><br><span class="line">      System.out.println(f1.exists());</span><br><span class="line">      //3.判断文件对象是否是文件</span><br><span class="line">      System.out.println(f1.isFile());</span><br><span class="line">      //4.判断文件对象是否是文件夹</span><br><span class="line">      System.out.println(f1.isDirectory());</span><br><span class="line">      //5.获取文件的名称</span><br><span class="line">      System.out.println(f1.getName());</span><br><span class="line">      //6.获取文件的大小，返回字节个数</span><br><span class="line">      System.out.println(f1.length());</span><br><span class="line">      //7.获取文件最后的修改时间</span><br><span class="line">      long time = f1.lastModified();</span><br><span class="line">      SimpleDateFormat sdf=new SimpleDateFormat(&quot;yyyy/MM/dd&quot;);</span><br><span class="line">      System.out.println(sdf.format(time));//2023/10/18</span><br><span class="line">      //8.获取创建文件对象时使用的路径</span><br><span class="line">      System.out.println(f1.getPath());</span><br><span class="line">      //9.获取文件对象的绝对路径</span><br><span class="line">      System.out.println(f1.getAbsolutePath());</span><br></pre></td></tr></table></figure><h3 id="3-创建、删除文件"><a href="#3-创建、删除文件" class="headerlink" title="3.创建、删除文件"></a>3.创建、删除文件</h3><p><strong>public boolean creatNewFile():</strong>创建一个新文件，创建成功返回true</p><p><strong>public boolean mkdir():</strong>创建文件夹（只能创建一级文件夹）</p><p><strong>public boolean mkdirs():</strong>创建文件夹,可以创建多级文件夹</p><p><strong>public boolean delete():</strong>删除文件或文件夹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//1.创建一个新文件</span><br><span class="line">      File f1=new File(&quot;./data/test2.txt&quot;);</span><br><span class="line">      System.out.println(f1.createNewFile());</span><br><span class="line">      //2.创建文件夹</span><br><span class="line">      File f2=new File(&quot;./data/a&quot;);</span><br><span class="line">      System.out.println(f2.mkdir());</span><br><span class="line">      //3.创建多个文件夹</span><br><span class="line">      File f3=new File(&quot;./data/1/2&quot;);</span><br><span class="line">      System.out.println(f3.mkdirs());</span><br><span class="line">      //4.删除文件或文件夹</span><br><span class="line">      System.out.println(f1.delete());</span><br><span class="line">      System.out.println(f2.delete());</span><br><span class="line">      System.out.println(f3.delete());</span><br><span class="line">      //&quot;./data/1&quot;这个文件夹还存在</span><br></pre></td></tr></table></figure><h3 id="4-遍历文件夹"><a href="#4-遍历文件夹" class="headerlink" title="4.遍历文件夹"></a>4.遍历文件夹</h3><p><img src="https://typoraimg.wangak.cc/2023/img/3.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">File f1=new File(&quot;./data&quot;);</span><br><span class="line">      //获取目录下文件的名称</span><br><span class="line">      String[] names=f1.list();</span><br><span class="line">      for(String x:names)&#123;</span><br><span class="line">          System.out.println(x);</span><br><span class="line">      &#125;</span><br><span class="line">      //获取当前目录下的文件对象</span><br><span class="line">      File[] files=f1.listFiles();</span><br><span class="line">      for (File file:files)&#123;</span><br><span class="line">          System.out.println(file.getPath());</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;File类&quot;&gt;&lt;a href=&quot;#File类&quot; class=&quot;headerlink&quot; title=&quot;File类&quot;&gt;&lt;/a&gt;File类&lt;/h2&gt;&lt;h3 id=&quot;1-创建File类的对象&quot;&gt;&lt;a href=&quot;#1-创建File类的对象&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="java" scheme="https://wangak.cc/categories/java/"/>
    
    
    <category term="java" scheme="https://wangak.cc/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>卷积编码位置信息</title>
    <link href="https://wangak.cc/posts/a8dea67.html"/>
    <id>https://wangak.cc/posts/a8dea67.html</id>
    <published>2023-10-13T06:56:14.000Z</published>
    <updated>2023-10-14T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>论文：《HOW MUCH POSITION INFORMATION DO CONVOLUTIONAL NEURAL NETWORKS ENCODE?》（ICLR2020）</strong></p><h3 id="论文内容："><a href="#论文内容：" class="headerlink" title="论文内容："></a>论文内容：</h3><h4 id="初步实验："><a href="#初步实验：" class="headerlink" title="初步实验："></a>初步实验：</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412926.png" alt="1"></p><p>对原始图像和裁剪过的图像进行显著性检测。</p><p>显著的区域分析，对于相同的物体，在不同的边缘下，显著性区域始终靠近图像中心。</p><p>推测：<strong>位置信息在 CNN 网络提取的特征图中被隐式编码</strong></p><h4 id="Position-Encoding-Network："><a href="#Position-Encoding-Network：" class="headerlink" title="Position Encoding Network："></a>Position Encoding Network：</h4><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412136.png" alt="2"></p><p><strong>a feed forward convolutional encoder network $f_{enc} $:</strong>使用预训练的VGG或者 ResNet，仅作为前馈网络，其参数不参与训练。为前馈网络的在五个卷积层产生的特征图，使用双线性插值缩放到统一尺寸进行拼接，之后输入到 Position Encoding Module 中。</p><p><strong>position encoding module：</strong>一般卷积网络，其卷积核未使用Padding。</p><p>作者使用该网络判断卷积层产生的特征图中是否包含位置信息。</p><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412155.png" alt="3" style="zoom: 80%;"></p><p>垂直（H)和水平(V)方向的梯度掩码、应用高斯滤波器来设计另一种类型的真值图，高斯分布(G)、水平和垂直条纹（HS、VS)，使用这五种图像表示位置信息，作为Ground Truth，每次训练选择其中一种，<strong>所有样本的标签都是一样的</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412681.png" alt="4" style="zoom:80%;"></p><p>除了使用数据集中的原始图像，作者还分别将<strong>纯黑、纯白、高斯噪声图像作为输入</strong>，这是为了验证在没有语义信息的情况下，特征中是否包含绝对位置信息。</p><p><strong>评价指标：</strong> Spearmen Correlation (<strong>SPC</strong>) and Mean Absoute Error (<strong>MAE</strong>)，前者越高说明输出与目标图像的相关性越高，后者则相反。</p><p><strong>实验结果:</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412217.png" alt="5"></p><p>单独使用PosENet得到的分数要低很多，这一结果表明，仅从输入图像中提取位置信息是非常困难的，<strong>PosENet要与编码器网络相结合才能更好地提取出位置信息</strong></p><p>发现基于ResNet的模型比基于VGG16的模型实现了更高的性能。</p><h4 id="探究卷积的参数对提取位置信息的影响"><a href="#探究卷积的参数对提取位置信息的影响" class="headerlink" title="探究卷积的参数对提取位置信息的影响"></a>探究卷积的参数对提取位置信息的影响</h4><p><strong>length of convolutional layers：</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412853.png" alt="6" style="zoom: 67%;"></p><p><strong>kernel size:</strong></p><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412339.png" alt="7" style="zoom: 80%;"></p><p>​                                                                <strong>更大的感受野可以更好地解析位置信息</strong></p><p><strong>zero-padding：</strong>作者认为卷积中zero-padding 是 CNN 中位置信息的来源</p><p><img src="https://typoraimg.wangak.cc/2023/img/202310201412058.png" alt="8" style="zoom:80%;"></p><p>从结果中可以看出，未添加 zero-padding 的 VGG16 的性能比默认设置（padding =  1）低得多。PosENet（padding = 1）实现了比原始（padding = 0）更高的性能，而当 padding 设置为 2  时，位置信息的作用更加明显。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;论文：《HOW MUCH POSITION INFORMATION DO CONVOLUTIONAL NEURAL NETWORKS ENCODE?》（ICLR2020）&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;论文内容：&quot;&gt;&lt;a href=&quot;#论文内容：</summary>
      
    
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="计算机视觉" scheme="https://wangak.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="深度学习" scheme="https://wangak.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="https://wangak.cc/tags/CNN/"/>
    
  </entry>
  
</feed>
